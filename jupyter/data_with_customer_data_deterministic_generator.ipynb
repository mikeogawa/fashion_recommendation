{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this Project, we will demonstrate how to use deep reinforcement learning to recommend good pairs of t-shirts and jeans to customers.  \n",
    "\n",
    "### Problem\n",
    "\n",
    "**Recommend users colored t-shirt and jeans that match their taste**\n",
    "\n",
    "\n",
    "### Key Assumption\n",
    "\n",
    "Here we will base our assumption based on the following:   \n",
    "- Users will be recommended colors of t-shirts and jeans, sequentially.\n",
    "- If the color does not match the user's taste, the the user will ask for another recommendation.\n",
    "- The recommendation system will recommend another color until the color matches the user's taste.\n",
    "\n",
    "### Detailed Assumption\n",
    "\n",
    "Here we will define the problem base on the following assumption:\n",
    "- The recommendation system will propose multiple colors of t-shirts, and then jeans.\n",
    "- After both are finished, episode terminates.\n",
    "- User's will not quite when asking for recommendation.\n",
    "- User's can be grouped into A and B, and each group has a taste distrubtion.\n",
    "- User's are defined based on 3 features.\n",
    "- User's will likely choose the color of their jeans that matches their t-shirt.\n",
    "- 6 colors will exist for t-shirts and jeans, respectively.\n",
    "- If the color matches the user's taste, we give a reward of +1, else -1.   \n",
    "    ex)    \n",
    "    If t-shirt and jeans were successfully recommended without making any mistakes, +2 reward is given.   \n",
    "    If both used all actions to guess user's taste, then total reward of -10 in episode is given.\n",
    "\n",
    "- If the color matches the user's taste, then it will change its target clothes.   \n",
    "    ex)   \n",
    "    If t-shirt recommendation succeeds, the recommendation system will recommend jeans.   \n",
    "    If jeans succeed, it will terminate the episode\n",
    "\n",
    "**Note**\n",
    "This notebook is based on groups choosing colors **deterministically**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.lamda.nju.edu.cn/yuy/GetFile.aspx?File=papers/kdd18-RobustDQN.pdf&AspxAutoDetectCookieSupport=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data=3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will generate user's unique data with 3 features.   \n",
    "We will generate x1 as Group A's data and x2 as Group B's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=np.random.normal(-1,0.1,(sample_data//2,3))\n",
    "x2=np.random.normal(1,0.1,(sample_data//2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-shirt and Jeans Consuming Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will generate purchase probability for groups A and B.   \n",
    "Here, we will assume users can choose 6 different colored t-shirt and jeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=np.array([0.02,0.9,0.02,0.02,0.02,0.02])\n",
    "p2=np.array([0.9,0.02,0.02,0.02,0.02,0.02])\n",
    "\n",
    "# p1=np.array([0,1,0,0,0,0])\n",
    "# p2=np.array([1,0,0,0,0,0])\n",
    "\n",
    "\n",
    "def shirt(idx):\n",
    "    pr=p1 if idx==0 else p2\n",
    "    pr = pr/pr.sum()\n",
    "    return np.random.choice(len(p1),p=pr)\n",
    "\n",
    "# if customer buys certain colored shirt, the customer will have a high probability of buying the same colored jeans\n",
    "def jeans(idx):\n",
    "    p_=np.zeros((len(p1),))\n",
    "    p_[idx]=1\n",
    "    pr=np.where(p_==1,1.0,0.0)\n",
    "    pr = pr/pr.sum()\n",
    "    return np.random.choice(len(p1),p=pr)\n",
    "\n",
    "# generates data\n",
    "def out_data_prob(idx,size):\n",
    "    res = np.zeros((size,2))\n",
    "    for i in range(size):\n",
    "        r=shirt(idx)\n",
    "        j=jeans(r)\n",
    "        res[i,0]=r\n",
    "        res[i,1]=j\n",
    "    return res\n",
    "    \n",
    "\n",
    "z1=out_data_prob(0,sample_data//2)\n",
    "z2=out_data_prob(1,sample_data//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=np.concatenate((x1,z1),axis=1)\n",
    "r2=np.concatenate((x2,z2),axis=1)\n",
    "\n",
    "dataset=np.concatenate([r1,r2],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modifying Filter of RenomRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "\n",
    "    return y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renom_rl.utility.filter import DiscreteNodeChooser\n",
    "from renom_rl.utility.fixer import transform_node_2_numpy\n",
    "\n",
    "class MaskMaxNodeChooser(DiscreteNodeChooser):\n",
    "\n",
    "    \n",
    "    def __call__(self,x,y):\n",
    "        return self.forward(x,y)\n",
    "    \n",
    "    def forward(self, node_var, mask):\n",
    "\n",
    "        node_var = transform_node_2_numpy(node_var)\n",
    "        \n",
    "        res = softmax(node_var - np.where(mask[None,...],0,100000))\n",
    "\n",
    "        max_list = np.argmax(res, axis=1).reshape((-1, 1))\n",
    "        \n",
    "        if len(max_list) == 1:\n",
    "            return int(max_list)\n",
    "        else:\n",
    "            return max_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import and Modify ReNomRL's DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ReNom RL and modify it.   \n",
    "For this recommendation system, we will use DQN.   \n",
    "To simplify what DQN is, DQN is an algorithm that chooses action based on expected future reward.   \n",
    "It explores action using epsilon greedy algorithm.   \n",
    "Exploitation and exploration rate shifts based on how much steps the agent takes.   \n",
    "For this example, we gradually shift the action decision from exploration to exploitation by steps.   \n",
    "For further understanding, go to renom.jp.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "from numbers import Number\n",
    "import inspect\n",
    "import renom as rm\n",
    "\n",
    "from renom_rl.utility.replaybuffer import ReplayBuffer\n",
    "from renom_rl import AgentBase\n",
    "from renom_rl.environ.env import BaseEnv\n",
    "from renom_rl.utility.gradients import GradientClipping\n",
    "from renom_rl.utility.filter import EpsilonGreedyFilter, EpsilonSLFilter, EpsilonCFilter, DiscreteNodeChooser, ProbNodeChooser, MaxNodeChooser\n",
    "from renom_rl.utility.logger import Logger, DQNLogger, AVAILABLE_KEYS\n",
    "from renom_rl.utility.fixer import fix_envs_testenvs, fix_single_env, fix_optimizer,\\\n",
    "    fix_action_range, check_shape, check_reset_method, check_output_state, \\\n",
    "    check_step_method, fix_logger, fix_tuple_shape, fix_instance, fix_loss_function, fix_instance2, \\\n",
    "    ArgumentCheck, decorator, test_decorator\n",
    "from renom_rl.utility.additional_modules import deepcopy\n",
    "\n",
    "_dqn_keys = AVAILABLE_KEYS[\"dqn\"][\"logger\"]\n",
    "_dqn_keys_epoch = AVAILABLE_KEYS[\"dqn\"][\"logger_epoch\"]\n",
    "\n",
    "\n",
    "class DQN(AgentBase):\n",
    "\n",
    "    def __init__(self, env, q_network, logger=None,\n",
    "                 batch_size=32, update_period=10000, train_frequency=4,\n",
    "                 optimizer=None, gamma=0.99, buffer=None,\n",
    "                 node_selector=None, test_node_selector=None,\n",
    "                 action_filter=None, test_action_filter=None,\n",
    "                 gradient_clipping=None, loss_func=None, initialize=True):\n",
    "\n",
    "        super(DQN, self).__init__()\n",
    "        local_init = locals()\n",
    "        self._arg_check = ArgumentCheck(list(local_init.keys()), remove=[\n",
    "                                        \"__class__\", \"self\", \"env\", \"q_network\", \"logger\"])\n",
    "\n",
    "        kwargs_set = lambda **kwargs: kwargs\n",
    "        self._arg_base = kwargs_set(batch_size=[None, int, fix_instance2, {\"positive\": True, \"non_neg\": True}],\n",
    "                                    update_period=[None, int, fix_instance2,\n",
    "                                                   {\"positive\": True, \"non_neg\": True}],\n",
    "                                    train_frequency=[None, int, fix_instance2,\n",
    "                                                     {\"positive\": True, \"non_neg\": True}],\n",
    "                                    optimizer=[rm.Rmsprop(lr=0.00025, g=0.95),\n",
    "                                               rm.Optimizer, fix_instance],\n",
    "                                    gamma=[None, float, fix_instance2, {\n",
    "                                        \"positive\": True, \"range\": [0., 1.]}],\n",
    "                                    buffer=[ReplayBuffer(), ReplayBuffer, fix_instance],\n",
    "                                    node_selector=[\n",
    "                                        MaskMaxNodeChooser(), DiscreteNodeChooser, fix_instance],\n",
    "                                    test_node_selector=[\n",
    "                                        MaskMaxNodeChooser(), DiscreteNodeChooser, fix_instance],\n",
    "                                    action_filter=[EpsilonSLFilter(epsilon_step=int(\n",
    "                                        0.8 * 50000)), EpsilonGreedyFilter, fix_instance],\n",
    "                                    test_action_filter=[\n",
    "                                        EpsilonCFilter(), EpsilonGreedyFilter, fix_instance],\n",
    "                                    gradient_clipping=[None, GradientClipping, fix_instance],\n",
    "                                    loss_func=[rm.ClippedMeanSquaredError(), None, fix_instance],\n",
    "                                    initialize=[None, bool, fix_instance2],\n",
    "                                    )\n",
    "        # Set Models.\n",
    "        self._q_network = fix_instance(q_network, None, rm.Model, \"q_network\")\n",
    "        self._target_q_network = deepcopy(self._q_network)\n",
    "        self._best_q_network = deepcopy(self._q_network)\n",
    "        # logger\n",
    "        self._logger = fix_logger(logger, _dqn_keys, _dqn_keys_epoch, DQNLogger())\n",
    "        # Check Env class type.\n",
    "        envs, test_env = fix_envs_testenvs(env)\n",
    "        self._env, self._test_env, state_shape, action_shape = fix_single_env(envs, test_env)\n",
    "\n",
    "        # Test\n",
    "        self._initial_env_check(state_shape, action_shape)\n",
    "\n",
    "        # Set common params\n",
    "        res = self._fixer(local_init)\n",
    "        for k, v in res.items():\n",
    "            self._arg_base[k][0] = v\n",
    "            self._arg_base[k][2] = fix_instance\n",
    "            self.__dict__[\"_%s\" % k] = v\n",
    "        self._loss_func = fix_loss_function(loss_func, rm.ClippedMeanSquaredError())\n",
    "        _ = self._buffer([1, ], state_shape)\n",
    "\n",
    "        # Reset Model\n",
    "        if initialize:\n",
    "            self._initializer()\n",
    "\n",
    "        # action_filter_during_fit\n",
    "        self._action_filter_during_fit = self._action_filter\n",
    "\n",
    "        # private info\n",
    "        self._private_info = {**local_init, **{k: v[0] for k, v in self._arg_base.items()}}\n",
    "        self._private_info_test = self._push_test_info()\n",
    "\n",
    "    def _initializer(self):\n",
    "        '''Target q-network is initialized with same neural network weights of q-network.'''\n",
    "        # Reset weight.\n",
    "        for layer in self._q_network.iter_models():\n",
    "            if hasattr(layer, \"params\"):\n",
    "                layer.params = {}\n",
    "\n",
    "        for layer in list(self._target_q_network.iter_models()):\n",
    "            if hasattr(layer, \"params\"):\n",
    "                layer.params = {}\n",
    "\n",
    "    def _initial_env_check(self, state_shape, action_shape):\n",
    "        '''Checks Shapes During Initalization'''\n",
    "\n",
    "        network = self._q_network\n",
    "        node_selector = MaskMaxNodeChooser()\n",
    "        test_env = self._test_env\n",
    "\n",
    "        # Check Env Reset\n",
    "        s = test_env.reset()\n",
    "        check_reset_method(s, state_shape)\n",
    "\n",
    "        # Check Network output length\n",
    "        net_out = network(s[None, :])\n",
    "        check_output_state(out=net_out, length=1, name=\"action\")\n",
    "\n",
    "        # Check Network shape\n",
    "        c_out = net_out.as_ndarray().shape[1:]\n",
    "        check_shape(target=action_shape, actual=c_out, shape_name=\"action\")\n",
    "\n",
    "        # Check Env Step\n",
    "        act = net_out.as_ndarray()\n",
    "        step_info = test_env.step(node_selector(act,test_env.mask()))\n",
    "        check_step_method(step_info, act, state_shape)\n",
    "\n",
    "    def _action(self, state, node_selector, env):\n",
    "        \"\"\"This method returns an action according to the given state.\n",
    "        \"\"\"\n",
    "        self._q_network.set_models(inference=True)\n",
    "        act = self._q_network(state[None, ...])\n",
    "        return node_selector(act,env.mask())\n",
    "\n",
    "    def _rec_copy(self, obj1, obj2):\n",
    "        \"\"\"This function copies the batch normalization parameters\"\"\"\n",
    "        for item_keys in obj1.__dict__.keys():\n",
    "            if isinstance(obj1.__dict__[item_keys], rm.BatchNormalize):\n",
    "                obj1.__dict__[item_keys]._mov_mean = obj2.__dict__[item_keys]._mov_mean\n",
    "                obj1.__dict__[item_keys]._mov_std = obj2.__dict__[item_keys]._mov_std\n",
    "            elif isinstance(obj1.__dict__[item_keys], rm.Model):\n",
    "                self._rec_copy(obj1.__dict__[item_keys], obj2.__dict__[item_keys])\n",
    "\n",
    "    def _update(self):\n",
    "        \"\"\"This function updates target network.\"\"\"\n",
    "        # A(B) Copy B to A.\n",
    "        self._target_q_network.copy_params(self._best_q_network)\n",
    "        self._rec_copy(self._target_q_network, self._best_q_network)\n",
    "\n",
    "    def _update_best_q_network(self):\n",
    "        \"\"\"This function updates best network in each target update period.\"\"\"\n",
    "        self._best_q_network.copy_params(self._q_network)\n",
    "        self._rec_copy(self._best_q_network, self._q_network)\n",
    "\n",
    "    @decorator([\"epoch\", \"epoch_step\", \"random_step\", \"test_step\"])\n",
    "    def fit(self, epoch=1, epoch_step=250000, random_step=50000,\n",
    "            batch_size=None, test_step=None,\n",
    "            update_period=None, train_frequency=None,\n",
    "            optimizer=None, gamma=None, buffer=None,\n",
    "            node_selector=None, test_node_selector=None,\n",
    "            action_filter=None, test_action_filter=None,\n",
    "            gradient_clipping=None, loss_func=None, initialize=None):\n",
    "\n",
    "        # acquiring arguments as local variables\n",
    "        epoch = fix_instance2(epoch, int, \"epoch\", positive=True, non_neg=True)\n",
    "        epoch_step = fix_instance2(epoch_step, int, \"epoch_step\", positive=True, non_neg=True)\n",
    "        random_step = fix_instance2(random_step, int, \"random_step\", positive=True)\n",
    "        test_step = fix_instance(test_step, None, None, \"test_step\", positive=True, non_neg=True)\n",
    "\n",
    "        _q_network = self._q_network\n",
    "        target_q_network = self._target_q_network\n",
    "        best_q_network = self._best_q_network\n",
    "        env = self._env\n",
    "        test_env = self._test_env\n",
    "        logger = self._logger\n",
    "        self._action_filter_during_fit = action_filter\n",
    "\n",
    "        buffer([1, ], test_env.state_shape)\n",
    "        buffer.set_network(_q_network,target_q_network,gamma)\n",
    "        loss_func = fix_loss_function(loss_func, rm.ClippedMeanSquaredError())\n",
    "        # Reset Model\n",
    "        if initialize:\n",
    "            self._initializer()\n",
    "\n",
    "        # random step phase\n",
    "        print(\"Run random {} step for storing experiences\".format(random_step))\n",
    "\n",
    "        state = env.reset()\n",
    "\n",
    "        # env start(after reset)\n",
    "        env.start()\n",
    "\n",
    "        for i in range(1, random_step + 1):\n",
    "            action = env.sample()\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            buffer.store(state, np.array(action),\n",
    "                         np.array(reward), next_state, np.array(terminal))\n",
    "            state = next_state\n",
    "            if terminal:\n",
    "                state = env.reset()\n",
    "\n",
    "        # History of Learning\n",
    "        max_reward_in_each_update_period = -np.Inf\n",
    "\n",
    "        count = 0  # update period\n",
    "        step_count = 0  # steps\n",
    "        episode_count = 0  # episodes\n",
    "\n",
    "        # 1 epoch stores multiple epoch steps thus 1 epoch can hold multiple episodes\n",
    "        for e in range(1, epoch + 1):\n",
    "            continuous_step = 0\n",
    "            continuous_step_log = 0\n",
    "            sum_reward = 0\n",
    "            sum_reward_log = 0\n",
    "            nth_episode = 0\n",
    "\n",
    "            logger.start(epoch_step)\n",
    "\n",
    "            # env epoch\n",
    "            env.epoch()\n",
    "\n",
    "            state = env.reset()\n",
    "            loss = 0\n",
    "\n",
    "            for j in range(epoch_step):\n",
    "                # for stop epoch after 1 step\n",
    "                if j and env.stop_epoch():\n",
    "                    continue\n",
    "\n",
    "                # set action\n",
    "                act = self._action(state, node_selector, env)\n",
    "                action = action_filter(act, env.sample(),\n",
    "                                       step=step_count, episode=episode_count, epoch=e)\n",
    "                greedy = action_filter.value()\n",
    "\n",
    "                # pass it to env\n",
    "                next_state, reward, terminal = env.step(action)\n",
    "\n",
    "                buffer.store(state, np.array(action),\n",
    "                             np.array(reward), next_state, np.array(terminal))\n",
    "\n",
    "               # env epoch step\n",
    "                env.epoch_step()\n",
    "\n",
    "                sum_reward += reward\n",
    "\n",
    "                if j % train_frequency == 0 and j:\n",
    "                    if len(buffer) > batch_size:\n",
    "                        train_prestate, train_action, train_reward, train_state, train_terminal = \\\n",
    "                            buffer.get_minibatch(batch_size)\n",
    "\n",
    "                        # getting q values as target reference\n",
    "                        _q_network.set_models(inference=True)\n",
    "                        target_q_network.set_models(inference=True)\n",
    "\n",
    "                        target = self._q_network(train_prestate).as_ndarray()\n",
    "\n",
    "                        target.setflags(write=True)\n",
    "                        value = np.amax(self._target_q_network(train_state).as_ndarray(),\n",
    "                                        axis=1, keepdims=True) * gamma * (~train_terminal[:, None])\n",
    "\n",
    "                        # getting target value\n",
    "                        for i in range(batch_size):\n",
    "                            a = train_action[i, 0].astype(np.integer)\n",
    "                            target[i, a] = train_reward[i] + value[i]\n",
    "\n",
    "                        # train\n",
    "                        _q_network.set_models(inference=False)\n",
    "                        with _q_network.train():\n",
    "                            z = self._q_network(train_prestate)\n",
    "                            ls = loss_func(z, target)\n",
    "                        grad = ls.grad()\n",
    "\n",
    "                        if gradient_clipping:\n",
    "                            gradient_clipping(grad)\n",
    "\n",
    "                        grad.update(optimizer)\n",
    "                        loss = np.sum(ls.as_ndarray())\n",
    "                        buffer.update()\n",
    "                        # train_loss += loss\n",
    "\n",
    "                if count % update_period == 0 and count:\n",
    "                    max_reward_in_each_update_period = -np.Inf\n",
    "                    self._update()\n",
    "                    count = 0\n",
    "                count += 1\n",
    "\n",
    "                # terminal reset\n",
    "                if terminal:\n",
    "                    if max_reward_in_each_update_period <= sum_reward:\n",
    "                        self._update_best_q_network()\n",
    "                        max_reward_in_each_update_period = sum_reward\n",
    "\n",
    "                    # train_sum_rewards_in_each_episode.append(sum_reward)\n",
    "                    # hold log values\n",
    "                    sum_reward_log = sum_reward\n",
    "                    continuous_step_log = continuous_step\n",
    "                    # reset log values\n",
    "                    sum_reward = 0\n",
    "                    continuous_step = 0\n",
    "                    # increment episode values\n",
    "                    nth_episode += 1\n",
    "                    episode_count += 1\n",
    "\n",
    "                    env.reset()\n",
    "\n",
    "                logger.update(1)\n",
    "                logger.logger(state=state, action=action, reward=reward,\n",
    "                              terminal=terminal, next_state=next_state,\n",
    "                              total_step=step_count, epoch_step=j, max_step=epoch_step,\n",
    "                              total_episode=episode_count, epoch_episode=nth_episode, steps_per_episode=continuous_step_log,\n",
    "                              epoch=e, max_epoch=epoch, loss=loss,\n",
    "                              sum_reward=sum_reward_log, epsilon=greedy)\n",
    "                # self.logger.update(1)\n",
    "\n",
    "                continuous_step += 1\n",
    "                step_count += 1\n",
    "                state = next_state\n",
    "\n",
    "                # if terminate executes, then do execute \"continue\"\n",
    "                if env.terminate() or env.terminate_epoch():\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                summed_test_reward = self.test(test_step, test_action_filter, test_node_selector)\n",
    "                logger.logger_epoch(total_episode=episode_count, epoch_episode=nth_episode,\n",
    "                                    epoch=e, max_epoch=epoch, test_reward=summed_test_reward, epsilon=greedy)\n",
    "                logger.close()\n",
    "                continue\n",
    "\n",
    "            logger.close()\n",
    "            if env.terminate():\n",
    "                break\n",
    "\n",
    "        # env close\n",
    "        env.close()\n",
    "\n",
    "    @test_decorator\n",
    "    def test(self, test_step=None, action_filter=None, node_selector=None):\n",
    "        \"\"\"\n",
    "        Test the trained agent.\n",
    "        Refer to ``DQN`` for other argument descriptions.\n",
    "\n",
    "        Args:\n",
    "            test_step (int, None): Number of steps (not episodes) for test. If None is given, this method tests execute only 1 episode.\n",
    "\n",
    "        Returns:\n",
    "            Sum of rewards. (float)\n",
    "        \"\"\"\n",
    "        env = self._test_env\n",
    "        # if filter_obj argument was specified, the change the object\n",
    "        test_step = fix_instance(test_step, None, int, \"test_step\", positive=True, non_neg=True)\n",
    "        # action_filter = fix_instance(action_filter, self._test_action_filter,\n",
    "        #                              EpsilonGreedyFilter, \"action_filter\")\n",
    "        # node_selector = fix_instance(node_selector, self._test_node_selector,\n",
    "        #                              DiscreteNodeChooser, \"node_selector\")\n",
    "        action_filter.check_instance(self._action_filter_during_fit)\n",
    "\n",
    "        sum_reward = 0\n",
    "        env.test_start()\n",
    "        state = env.reset()\n",
    "\n",
    "        if test_step is None:\n",
    "            while True:\n",
    "                action = action_filter.test(self._action(\n",
    "                    state, node_selector, env), env.sample())\n",
    "\n",
    "                state, reward, terminal = env.step(action)\n",
    "\n",
    "                sum_reward += float(reward)\n",
    "\n",
    "                env.test_epoch_step()\n",
    "\n",
    "                if terminal or env.test_terminate():\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            for j in range(test_step):\n",
    "                action = action_filter.test(self._action(\n",
    "                    state, node_selector, env), env.sample())\n",
    "\n",
    "                state, reward, terminal = env.step(action)\n",
    "\n",
    "                sum_reward += float(reward)\n",
    "\n",
    "                env.test_epoch_step()\n",
    "\n",
    "                if terminal:\n",
    "                    env.reset()\n",
    "\n",
    "                if env.test_terminate():\n",
    "                    break\n",
    "\n",
    "        env.test_close()\n",
    "\n",
    "        return sum_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renom_rl.environ import BaseEnv\n",
    "# from renom_rl.discrete.dqn import DQN\n",
    "import renom as rm\n",
    "from renom_rl.utility.filter import EpsilonSLFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Defining NN and Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(rm.Model):\n",
    "    def __init__(self):\n",
    "        self.d1=rm.Dense(32)\n",
    "        self.d2=rm.Dense(32)\n",
    "        self.d3=rm.Dense(len(p1))\n",
    "        self.r=rm.Relu()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h=self.d1(x)\n",
    "        h=self.r(h)\n",
    "        h=self.d2(h)\n",
    "        h=self.r(h)\n",
    "        h=self.d3(h)\n",
    "        return h\n",
    "model=NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerEnv(BaseEnv):\n",
    "    def __init__(self, dataset, randomness=True):\n",
    "        self.action_shape=(len(p1),)\n",
    "        self.state_shape=(3+len(p1)*2,)\n",
    "        \n",
    "        self.idx = 0\n",
    "        self.l = len(dataset)\n",
    "        self.randomness = randomness\n",
    "        self.in_data = dataset[:,0:3]\n",
    "        self.out_data = dataset[:,3:5]\n",
    "        self.mode = 0\n",
    "        self._a_list=[]\n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        self._a_list = []\n",
    "        self.mode = 0\n",
    "        self.state = np.concatenate((self.in_data[self.idx],np.zeros((len(p1)*2,)))) \n",
    "        if self.randomness:\n",
    "            self.idx = np.random.randint(self.l)\n",
    "        else:\n",
    "            self.inc()\n",
    "    \n",
    "        return self.state\n",
    "        \n",
    "    def step(self,action):\n",
    "        target = self.out_data[self.idx,self.mode]\n",
    "\n",
    "        if action in self._a_list:\n",
    "            raise Exception(\"{} already in list\".format(action))\n",
    "\n",
    "        self._a_list.append(action)\n",
    "            \n",
    "        if target==action:\n",
    "            reward = 1\n",
    "            \n",
    "            if self.mode == 0:\n",
    "                self.state[3+action]=1\n",
    "            else:\n",
    "                self.state[3+len(p1)+action]=1\n",
    "                \n",
    "            self.mode += 1\n",
    "            self._a_list = []\n",
    "            terminal = True if self.mode > 1 else False\n",
    "            \n",
    "        else:\n",
    "            reward = -1\n",
    "            terminal = False\n",
    "        \n",
    "        return self.state, reward, terminal\n",
    "    \n",
    "    def avail(self):\n",
    "        a_list = np.array(self._a_list)\n",
    "        a_range = np.arange(*self.action_shape)\n",
    "        a_avail = np.where(np.isin(a_range,a_list),0,1)\n",
    "        return  a_avail\n",
    "    \n",
    "    def sample(self):\n",
    "        \n",
    "        a_avail = self.avail()\n",
    "        tot = a_avail.sum()\n",
    "        a_prob = a_avail/tot if tot > 0 else a_avail\n",
    "\n",
    "        return np.random.choice(len(a_prob),p=a_prob)\n",
    "    \n",
    "    def index(self,x):\n",
    "        self.idx=x\n",
    "        \n",
    "    def inc(self):\n",
    "        self.idx += 1\n",
    "        self.idx %= self.l\n",
    "    \n",
    "    def mask(self):\n",
    "        \n",
    "        return self.avail()\n",
    "\n",
    "train_env=CustomerEnv(dataset)\n",
    "test_env=CustomerEnv(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn=DQN([train_env,test_env],\n",
    "        model,\n",
    "        gamma=0.0,\n",
    "        optimizer=rm.Adam(lr=0.001),\n",
    "        action_filter=EpsilonSLFilter(epsilon_step=20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0001 epsilon 0.9981 loss 0.5354 rewards in epoch -17.000 episode 0005 rewards in episode -3.000.:   0%|          | 39/22000 [00:00<01:46, 206.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run random 0 step for storing experiences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 001 avg_loss:0.0980 total reward in epoch: [train:-2868.000 test: 2.0] avg train reward in episode:-0.599 epsilon :0.000: 100%|██████████| 22000/22000 [02:56<00:00, 124.90it/s]\n"
     ]
    }
   ],
   "source": [
    "dqn.fit(epoch=1,epoch_step=22000,random_step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Result\n",
    "\n",
    "Here we show the reward for each epsiode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dqn._logger.graph(\"sum_reward\",average_range=[3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  14.,   37.,   67.,  135.,  221.,  719.,  525.,  505.,  543.,\n",
       "        2017.]),\n",
       " array([-8., -7., -6., -5., -4., -3., -2., -1.,  0.,  1.,  2.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(dqn._logger.result()[\"sum_reward\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the reward graph, we can observe the agent is making multiple mistakes in the beginning, but as it experience more steps, the agent gradually generates better reward value per episode.    \n",
    "The histogram of the reward represents the frequency of the total reward. From the reward graph, it might be seen as an oscilating graph, but from the histogram, we can observe that the agent is scoring +2 reward frequently, thus we can tell the agent is scoring good during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.17120278 [[0.17037053 0.16989592 0.16357096 0.17120278 0.15617071 0.16878913]]\n",
      "1 0.17870916 [[0.16950336 0.17870916 0.15805323 0.16402765 0.16073671 0.1689699 ]]\n"
     ]
    }
   ],
   "source": [
    "res1=softmax(model(np.array([1,1,1]+[0 for _ in range(6)]+[0 for _ in range(6)])[None,...]))\n",
    "print(0,np.max(res1),res1)\n",
    "res2=softmax(model(np.array([-1,-1,-1]+[0 for _ in range(6)]+[0 for _ in range(6)])[None,...]))\n",
    "print(1,np.max(res2),res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
