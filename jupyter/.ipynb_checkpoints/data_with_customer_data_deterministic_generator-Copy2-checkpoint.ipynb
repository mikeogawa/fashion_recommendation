{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this Project, we will demonstrate how to use deep reinforcement learning to recommend good pairs of t-shirts and jeans to customers.  \n",
    "\n",
    "### Problem\n",
    "\n",
    "**Recommend users colored t-shirt and jeans that match their taste**\n",
    "\n",
    "\n",
    "### Key Assumption\n",
    "\n",
    "Here we will base our assumption based on the following:   \n",
    "- Users will be recommended colors of t-shirts and jeans, sequentially.\n",
    "- If the color does not match the user's taste, the the user will ask for another recommendation.\n",
    "- The recommendation system will recommend another color until the color matches the user's taste.\n",
    "\n",
    "### Detailed Assumption\n",
    "\n",
    "Here we will define the problem base on the following assumption:\n",
    "- The recommendation system will propose multiple colors of t-shirts, and then jeans.\n",
    "- After both are finished, episode terminates.\n",
    "- User's will not quite when asking for recommendation.\n",
    "- User's can be grouped into A and B, and each group has a taste distrubtion.\n",
    "- User's are defined based on 3 features.\n",
    "- User's will likely choose the color of their jeans that matches their t-shirt.\n",
    "- 6 colors will exist for t-shirts and jeans, respectively.\n",
    "- If the color matches the user's taste, we give a reward of +1, else -1.   \n",
    "    ex)    \n",
    "    If t-shirt and jeans were successfully recommended without making any mistakes, +2 reward is given.   \n",
    "    If both used all actions to guess user's taste, then total reward of -10 in episode is given.\n",
    "\n",
    "- If the color matches the user's taste, then it will change its target clothes.   \n",
    "    ex)   \n",
    "    If t-shirt recommendation succeeds, the recommendation system will recommend jeans.   \n",
    "    If jeans succeed, it will terminate the episode\n",
    "\n",
    "**Note**\n",
    "This notebook is based on groups choosing colors **deterministically**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.lamda.nju.edu.cn/yuy/GetFile.aspx?File=papers/kdd18-RobustDQN.pdf&AspxAutoDetectCookieSupport=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data=3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will generate user's unique data with 3 features.   \n",
    "We will generate x1 as Group A's data and x2 as Group B's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=np.random.normal(-1,0.1,(sample_data//2,3))\n",
    "x2=np.random.normal(1,0.1,(sample_data//2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-shirt and Jeans Consuming Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will generate purchase probability for groups A and B.   \n",
    "Here, we will assume users can choose 6 different colored t-shirt and jeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=np.array([0.02,0.9,0.02,0.02,0.02,0.02])\n",
    "p2=np.array([0.9,0.02,0.02,0.02,0.02,0.02])\n",
    "\n",
    "# p1=np.array([0,1,0,0,0,0])\n",
    "# p2=np.array([1,0,0,0,0,0])\n",
    "\n",
    "\n",
    "def shirt(idx):\n",
    "    pr=p1 if idx==0 else p2\n",
    "    pr = pr/pr.sum()\n",
    "    return np.random.choice(len(p1),p=pr)\n",
    "\n",
    "# if customer buys certain colored shirt, the customer will have a high probability of buying the same colored jeans\n",
    "def jeans(idx):\n",
    "    p_=np.zeros((len(p1),))\n",
    "    p_[idx]=1\n",
    "    pr=np.where(p_==1,1.0,0.0)\n",
    "    pr = pr/pr.sum()\n",
    "    return np.random.choice(len(p1),p=pr)\n",
    "\n",
    "# generates data\n",
    "def out_data_prob(idx,size):\n",
    "    res = np.zeros((size,2))\n",
    "    for i in range(size):\n",
    "        r=shirt(idx)\n",
    "        j=jeans(r)\n",
    "        res[i,0]=r\n",
    "        res[i,1]=j\n",
    "    return res\n",
    "    \n",
    "\n",
    "z1=out_data_prob(0,sample_data//2)\n",
    "z2=out_data_prob(1,sample_data//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=np.concatenate((x1,z1),axis=1)\n",
    "r2=np.concatenate((x2,z2),axis=1)\n",
    "\n",
    "dataset=np.concatenate([r1,r2],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modifying Filter of RenomRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "\n",
    "    return y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renom_rl.utility.filter import DiscreteNodeChooser\n",
    "from renom_rl.utility.fixer import transform_node_2_numpy\n",
    "\n",
    "class MaskMaxNodeChooser(DiscreteNodeChooser):\n",
    "\n",
    "    \n",
    "    def __call__(self,x,y):\n",
    "        return self.forward(x,y)\n",
    "    \n",
    "    def forward(self, node_var, mask):\n",
    "\n",
    "        node_var = transform_node_2_numpy(node_var)\n",
    "        \n",
    "        res = softmax(node_var - np.where(mask[None,...],0,100000))\n",
    "\n",
    "        max_list = np.argmax(res, axis=1).reshape((-1, 1))\n",
    "        \n",
    "        if len(max_list) == 1:\n",
    "            return int(max_list)\n",
    "        else:\n",
    "            return max_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import and Modify ReNomRL's DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ReNom RL and modify it.   \n",
    "For this recommendation system, we will use DQN.   \n",
    "To simplify what DQN is, DQN is an algorithm that chooses action based on expected future reward.   \n",
    "It explores action using epsilon greedy algorithm.   \n",
    "Exploitation and exploration rate shifts based on how much steps the agent takes.   \n",
    "For this example, we gradually shift the action decision from exploration to exploitation by steps.   \n",
    "For further understanding, go to renom.jp.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "from numbers import Number\n",
    "import inspect\n",
    "import renom as rm\n",
    "\n",
    "from renom_rl.utility.replaybuffer import ReplayBuffer\n",
    "from renom_rl import AgentBase\n",
    "from renom_rl.environ.env import BaseEnv\n",
    "from renom_rl.utility.gradients import GradientClipping\n",
    "from renom_rl.utility.filter import EpsilonGreedyFilter, EpsilonSLFilter, EpsilonCFilter, DiscreteNodeChooser, ProbNodeChooser, MaxNodeChooser\n",
    "from renom_rl.utility.logger import Logger, DQNLogger, AVAILABLE_KEYS\n",
    "from renom_rl.utility.fixer import fix_envs_testenvs, fix_single_env, fix_optimizer,\\\n",
    "    fix_action_range, check_shape, check_reset_method, check_output_state, \\\n",
    "    check_step_method, fix_logger, fix_tuple_shape, fix_instance, fix_loss_function, fix_instance2, \\\n",
    "    ArgumentCheck, decorator, test_decorator\n",
    "from renom_rl.utility.additional_modules import deepcopy\n",
    "\n",
    "_dqn_keys = AVAILABLE_KEYS[\"dqn\"][\"logger\"]\n",
    "_dqn_keys_epoch = AVAILABLE_KEYS[\"dqn\"][\"logger_epoch\"]\n",
    "\n",
    "\n",
    "class DQN(AgentBase):\n",
    "\n",
    "    def __init__(self, env, q_network, logger=None,\n",
    "                 batch_size=32, update_period=10000, train_frequency=4,\n",
    "                 optimizer=None, gamma=0.99, buffer=None,\n",
    "                 node_selector=None, test_node_selector=None,\n",
    "                 action_filter=None, test_action_filter=None,\n",
    "                 gradient_clipping=None, loss_func=None, initialize=True):\n",
    "\n",
    "        super(DQN, self).__init__()\n",
    "        local_init = locals()\n",
    "        self._arg_check = ArgumentCheck(list(local_init.keys()), remove=[\n",
    "                                        \"__class__\", \"self\", \"env\", \"q_network\", \"logger\"])\n",
    "\n",
    "        kwargs_set = lambda **kwargs: kwargs\n",
    "        self._arg_base = kwargs_set(batch_size=[None, int, fix_instance2, {\"positive\": True, \"non_neg\": True}],\n",
    "                                    update_period=[None, int, fix_instance2,\n",
    "                                                   {\"positive\": True, \"non_neg\": True}],\n",
    "                                    train_frequency=[None, int, fix_instance2,\n",
    "                                                     {\"positive\": True, \"non_neg\": True}],\n",
    "                                    optimizer=[rm.Rmsprop(lr=0.00025, g=0.95),\n",
    "                                               rm.Optimizer, fix_instance],\n",
    "                                    gamma=[None, float, fix_instance2, {\n",
    "                                        \"positive\": True, \"range\": [0., 1.]}],\n",
    "                                    buffer=[ReplayBuffer(), ReplayBuffer, fix_instance],\n",
    "                                    node_selector=[\n",
    "                                        MaskMaxNodeChooser(), DiscreteNodeChooser, fix_instance],\n",
    "                                    test_node_selector=[\n",
    "                                        MaskMaxNodeChooser(), DiscreteNodeChooser, fix_instance],\n",
    "                                    action_filter=[EpsilonSLFilter(epsilon_step=int(\n",
    "                                        0.8 * 50000)), EpsilonGreedyFilter, fix_instance],\n",
    "                                    test_action_filter=[\n",
    "                                        EpsilonCFilter(), EpsilonGreedyFilter, fix_instance],\n",
    "                                    gradient_clipping=[None, GradientClipping, fix_instance],\n",
    "                                    loss_func=[rm.ClippedMeanSquaredError(), None, fix_instance],\n",
    "                                    initialize=[None, bool, fix_instance2],\n",
    "                                    )\n",
    "        # Set Models.\n",
    "        self._q_network = fix_instance(q_network, None, rm.Model, \"q_network\")\n",
    "        self._target_q_network = deepcopy(self._q_network)\n",
    "        self._best_q_network = deepcopy(self._q_network)\n",
    "        # logger\n",
    "        self._logger = fix_logger(logger, _dqn_keys, _dqn_keys_epoch, DQNLogger())\n",
    "        # Check Env class type.\n",
    "        envs, test_env = fix_envs_testenvs(env)\n",
    "        self._env, self._test_env, state_shape, action_shape = fix_single_env(envs, test_env)\n",
    "\n",
    "        # Test\n",
    "        self._initial_env_check(state_shape, action_shape)\n",
    "\n",
    "        # Set common params\n",
    "        res = self._fixer(local_init)\n",
    "        for k, v in res.items():\n",
    "            self._arg_base[k][0] = v\n",
    "            self._arg_base[k][2] = fix_instance\n",
    "            self.__dict__[\"_%s\" % k] = v\n",
    "        self._loss_func = fix_loss_function(loss_func, rm.ClippedMeanSquaredError())\n",
    "        _ = self._buffer([1, ], state_shape)\n",
    "\n",
    "        # Reset Model\n",
    "        if initialize:\n",
    "            self._initializer()\n",
    "\n",
    "        # action_filter_during_fit\n",
    "        self._action_filter_during_fit = self._action_filter\n",
    "\n",
    "        # private info\n",
    "        self._private_info = {**local_init, **{k: v[0] for k, v in self._arg_base.items()}}\n",
    "        self._private_info_test = self._push_test_info()\n",
    "\n",
    "    def _initializer(self):\n",
    "        '''Target q-network is initialized with same neural network weights of q-network.'''\n",
    "        # Reset weight.\n",
    "        for layer in self._q_network.iter_models():\n",
    "            if hasattr(layer, \"params\"):\n",
    "                layer.params = {}\n",
    "\n",
    "        for layer in list(self._target_q_network.iter_models()):\n",
    "            if hasattr(layer, \"params\"):\n",
    "                layer.params = {}\n",
    "\n",
    "    def _initial_env_check(self, state_shape, action_shape):\n",
    "        '''Checks Shapes During Initalization'''\n",
    "\n",
    "        network = self._q_network\n",
    "        node_selector = MaskMaxNodeChooser()\n",
    "        test_env = self._test_env\n",
    "\n",
    "        # Check Env Reset\n",
    "        s = test_env.reset()\n",
    "        check_reset_method(s, state_shape)\n",
    "\n",
    "        # Check Network output length\n",
    "        net_out = network(s[None, :])\n",
    "        check_output_state(out=net_out, length=1, name=\"action\")\n",
    "\n",
    "        # Check Network shape\n",
    "        c_out = net_out.as_ndarray().shape[1:]\n",
    "        check_shape(target=action_shape, actual=c_out, shape_name=\"action\")\n",
    "\n",
    "        # Check Env Step\n",
    "        act = net_out.as_ndarray()\n",
    "        step_info = test_env.step(node_selector(act,test_env.mask()))\n",
    "        check_step_method(step_info, act, state_shape)\n",
    "\n",
    "    def _action(self, state, node_selector, env):\n",
    "        \"\"\"This method returns an action according to the given state.\n",
    "        \"\"\"\n",
    "        self._q_network.set_models(inference=True)\n",
    "        act = self._q_network(state[None, ...])\n",
    "        return node_selector(act,env.mask())\n",
    "\n",
    "    def _rec_copy(self, obj1, obj2):\n",
    "        \"\"\"This function copies the batch normalization parameters\"\"\"\n",
    "        for item_keys in obj1.__dict__.keys():\n",
    "            if isinstance(obj1.__dict__[item_keys], rm.BatchNormalize):\n",
    "                obj1.__dict__[item_keys]._mov_mean = obj2.__dict__[item_keys]._mov_mean\n",
    "                obj1.__dict__[item_keys]._mov_std = obj2.__dict__[item_keys]._mov_std\n",
    "            elif isinstance(obj1.__dict__[item_keys], rm.Model):\n",
    "                self._rec_copy(obj1.__dict__[item_keys], obj2.__dict__[item_keys])\n",
    "\n",
    "    def _update(self):\n",
    "        \"\"\"This function updates target network.\"\"\"\n",
    "        # A(B) Copy B to A.\n",
    "        self._target_q_network.copy_params(self._best_q_network)\n",
    "        self._rec_copy(self._target_q_network, self._best_q_network)\n",
    "\n",
    "    def _update_best_q_network(self):\n",
    "        \"\"\"This function updates best network in each target update period.\"\"\"\n",
    "        self._best_q_network.copy_params(self._q_network)\n",
    "        self._rec_copy(self._best_q_network, self._q_network)\n",
    "\n",
    "    @decorator([\"epoch\", \"epoch_step\", \"random_step\", \"test_step\"])\n",
    "    def fit(self, epoch=1, epoch_step=250000, random_step=50000,\n",
    "            batch_size=None, test_step=None,\n",
    "            update_period=None, train_frequency=None,\n",
    "            optimizer=None, gamma=None, buffer=None,\n",
    "            node_selector=None, test_node_selector=None,\n",
    "            action_filter=None, test_action_filter=None,\n",
    "            gradient_clipping=None, loss_func=None, initialize=None):\n",
    "\n",
    "        # acquiring arguments as local variables\n",
    "        epoch = fix_instance2(epoch, int, \"epoch\", positive=True, non_neg=True)\n",
    "        epoch_step = fix_instance2(epoch_step, int, \"epoch_step\", positive=True, non_neg=True)\n",
    "        random_step = fix_instance2(random_step, int, \"random_step\", positive=True)\n",
    "        test_step = fix_instance(test_step, None, None, \"test_step\", positive=True, non_neg=True)\n",
    "\n",
    "        _q_network = self._q_network\n",
    "        target_q_network = self._target_q_network\n",
    "        best_q_network = self._best_q_network\n",
    "        env = self._env\n",
    "        test_env = self._test_env\n",
    "        logger = self._logger\n",
    "        self._action_filter_during_fit = action_filter\n",
    "\n",
    "        buffer([1, ], test_env.state_shape)\n",
    "        buffer.set_network(_q_network,target_q_network,gamma)\n",
    "        loss_func = fix_loss_function(loss_func, rm.ClippedMeanSquaredError())\n",
    "        # Reset Model\n",
    "        if initialize:\n",
    "            self._initializer()\n",
    "\n",
    "        # random step phase\n",
    "        print(\"Run random {} step for storing experiences\".format(random_step))\n",
    "\n",
    "        state = env.reset()\n",
    "\n",
    "        # env start(after reset)\n",
    "        env.start()\n",
    "\n",
    "        for i in range(1, random_step + 1):\n",
    "            action = env.sample()\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "\n",
    "            buffer.store(state, np.array(action),\n",
    "                         np.array(reward), next_state, np.array(terminal))\n",
    "            state = next_state\n",
    "            if terminal:\n",
    "                state = env.reset()\n",
    "\n",
    "        # History of Learning\n",
    "        max_reward_in_each_update_period = -np.Inf\n",
    "\n",
    "        count = 0  # update period\n",
    "        step_count = 0  # steps\n",
    "        episode_count = 0  # episodes\n",
    "\n",
    "        # 1 epoch stores multiple epoch steps thus 1 epoch can hold multiple episodes\n",
    "        for e in range(1, epoch + 1):\n",
    "            continuous_step = 0\n",
    "            continuous_step_log = 0\n",
    "            sum_reward = 0\n",
    "            sum_reward_log = 0\n",
    "            nth_episode = 0\n",
    "\n",
    "            logger.start(epoch_step)\n",
    "\n",
    "            # env epoch\n",
    "            env.epoch()\n",
    "\n",
    "            state = env.reset()\n",
    "            loss = 0\n",
    "\n",
    "            for j in range(epoch_step):\n",
    "                # for stop epoch after 1 step\n",
    "                if j and env.stop_epoch():\n",
    "                    continue\n",
    "\n",
    "                # set action\n",
    "                act = self._action(state, node_selector, env)\n",
    "                action = action_filter(act, env.sample(),\n",
    "                                       step=step_count, episode=episode_count, epoch=e)\n",
    "                greedy = action_filter.value()\n",
    "\n",
    "                # pass it to env\n",
    "                next_state, reward, terminal = env.step(action)\n",
    "\n",
    "                buffer.store(state, np.array(action),\n",
    "                             np.array(reward), next_state, np.array(terminal))\n",
    "\n",
    "               # env epoch step\n",
    "                env.epoch_step()\n",
    "\n",
    "                sum_reward += reward\n",
    "\n",
    "                if j % train_frequency == 0 and j:\n",
    "                    if len(buffer) > batch_size:\n",
    "                        train_prestate, train_action, train_reward, train_state, train_terminal = \\\n",
    "                            buffer.get_minibatch(batch_size)\n",
    "\n",
    "                        # getting q values as target reference\n",
    "                        _q_network.set_models(inference=True)\n",
    "                        target_q_network.set_models(inference=True)\n",
    "\n",
    "                        target = self._q_network(train_prestate).as_ndarray()\n",
    "\n",
    "                        target.setflags(write=True)\n",
    "                        value = np.amax(self._target_q_network(train_state).as_ndarray(),\n",
    "                                        axis=1, keepdims=True) * gamma * (~train_terminal[:, None])\n",
    "\n",
    "                        # getting target value\n",
    "                        for i in range(batch_size):\n",
    "                            a = train_action[i, 0].astype(np.integer)\n",
    "                            target[i, a] = train_reward[i] + value[i]\n",
    "\n",
    "                        # train\n",
    "                        _q_network.set_models(inference=False)\n",
    "                        with _q_network.train():\n",
    "                            z = self._q_network(train_prestate)\n",
    "                            ls = loss_func(z, target)\n",
    "                        grad = ls.grad()\n",
    "\n",
    "                        if gradient_clipping:\n",
    "                            gradient_clipping(grad)\n",
    "\n",
    "                        grad.update(optimizer)\n",
    "                        loss = np.sum(ls.as_ndarray())\n",
    "                        buffer.update()\n",
    "                        # train_loss += loss\n",
    "\n",
    "                if count % update_period == 0 and count:\n",
    "                    max_reward_in_each_update_period = -np.Inf\n",
    "                    self._update()\n",
    "                    count = 0\n",
    "                count += 1\n",
    "\n",
    "                # terminal reset\n",
    "                if terminal:\n",
    "                    if max_reward_in_each_update_period <= sum_reward:\n",
    "                        self._update_best_q_network()\n",
    "                        max_reward_in_each_update_period = sum_reward\n",
    "\n",
    "                    # train_sum_rewards_in_each_episode.append(sum_reward)\n",
    "                    # hold log values\n",
    "                    sum_reward_log = sum_reward\n",
    "                    continuous_step_log = continuous_step\n",
    "                    # reset log values\n",
    "                    sum_reward = 0\n",
    "                    continuous_step = 0\n",
    "                    # increment episode values\n",
    "                    nth_episode += 1\n",
    "                    episode_count += 1\n",
    "\n",
    "                    env.reset()\n",
    "\n",
    "                logger.update(1)\n",
    "                logger.logger(state=state, action=action, reward=reward,\n",
    "                              terminal=terminal, next_state=next_state,\n",
    "                              total_step=step_count, epoch_step=j, max_step=epoch_step,\n",
    "                              total_episode=episode_count, epoch_episode=nth_episode, steps_per_episode=continuous_step_log,\n",
    "                              epoch=e, max_epoch=epoch, loss=loss,\n",
    "                              sum_reward=sum_reward_log, epsilon=greedy)\n",
    "                # self.logger.update(1)\n",
    "\n",
    "                continuous_step += 1\n",
    "                step_count += 1\n",
    "                state = next_state\n",
    "\n",
    "                # if terminate executes, then do execute \"continue\"\n",
    "                if env.terminate() or env.terminate_epoch():\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                summed_test_reward = self.test(test_step, test_action_filter, test_node_selector)\n",
    "                logger.logger_epoch(total_episode=episode_count, epoch_episode=nth_episode,\n",
    "                                    epoch=e, max_epoch=epoch, test_reward=summed_test_reward, epsilon=greedy)\n",
    "                logger.close()\n",
    "                continue\n",
    "\n",
    "            logger.close()\n",
    "            if env.terminate():\n",
    "                break\n",
    "\n",
    "        # env close\n",
    "        env.close()\n",
    "\n",
    "    @test_decorator\n",
    "    def test(self, test_step=None, action_filter=None, node_selector=None):\n",
    "        \"\"\"\n",
    "        Test the trained agent.\n",
    "        Refer to ``DQN`` for other argument descriptions.\n",
    "\n",
    "        Args:\n",
    "            test_step (int, None): Number of steps (not episodes) for test. If None is given, this method tests execute only 1 episode.\n",
    "\n",
    "        Returns:\n",
    "            Sum of rewards. (float)\n",
    "        \"\"\"\n",
    "        env = self._test_env\n",
    "        # if filter_obj argument was specified, the change the object\n",
    "        test_step = fix_instance(test_step, None, int, \"test_step\", positive=True, non_neg=True)\n",
    "        # action_filter = fix_instance(action_filter, self._test_action_filter,\n",
    "        #                              EpsilonGreedyFilter, \"action_filter\")\n",
    "        # node_selector = fix_instance(node_selector, self._test_node_selector,\n",
    "        #                              DiscreteNodeChooser, \"node_selector\")\n",
    "        action_filter.check_instance(self._action_filter_during_fit)\n",
    "\n",
    "        sum_reward = 0\n",
    "        env.test_start()\n",
    "        state = env.reset()\n",
    "\n",
    "        if test_step is None:\n",
    "            while True:\n",
    "                action = action_filter.test(self._action(\n",
    "                    state, node_selector, env), env.sample())\n",
    "\n",
    "                state, reward, terminal = env.step(action)\n",
    "\n",
    "                sum_reward += float(reward)\n",
    "\n",
    "                env.test_epoch_step()\n",
    "\n",
    "                if terminal or env.test_terminate():\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            for j in range(test_step):\n",
    "                action = action_filter.test(self._action(\n",
    "                    state, node_selector, env), env.sample())\n",
    "\n",
    "                state, reward, terminal = env.step(action)\n",
    "\n",
    "                sum_reward += float(reward)\n",
    "\n",
    "                env.test_epoch_step()\n",
    "\n",
    "                if terminal:\n",
    "                    env.reset()\n",
    "\n",
    "                if env.test_terminate():\n",
    "                    break\n",
    "\n",
    "        env.test_close()\n",
    "\n",
    "        return sum_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renom_rl.environ import BaseEnv\n",
    "# from renom_rl.discrete.dqn import DQN\n",
    "import renom as rm\n",
    "from renom_rl.utility.filter import EpsilonSLFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Defining NN and Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(rm.Model):\n",
    "    def __init__(self):\n",
    "        self.d1=rm.Dense(32)\n",
    "        self.d2=rm.Dense(32)\n",
    "        self.d3=rm.Dense(len(p1))\n",
    "        self.r=rm.Relu()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h=self.d1(x)\n",
    "        h=self.r(h)\n",
    "        h=self.d2(h)\n",
    "        h=self.r(h)\n",
    "        h=self.d3(h)\n",
    "        return h\n",
    "model=NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerEnv(BaseEnv):\n",
    "    def __init__(self, dataset, randomness=True):\n",
    "        self.action_shape=(len(p1),)\n",
    "        self.state_shape=(3+len(p1)*2,)\n",
    "        \n",
    "        self.idx = 0\n",
    "        self.l = len(dataset)\n",
    "        self.randomness = randomness\n",
    "        self.in_data = dataset[:,0:3]\n",
    "        self.out_data = dataset[:,3:5]\n",
    "        self.mode = 0\n",
    "        self._a_list=[]\n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        self._a_list = []\n",
    "        self.mode = 0\n",
    "        self.state = np.concatenate((self.in_data[self.idx],np.zeros((len(p1)*2,)))) \n",
    "        if self.randomness:\n",
    "            self.idx = np.random.randint(self.l)\n",
    "        else:\n",
    "            self.inc()\n",
    "    \n",
    "        return self.state\n",
    "        \n",
    "    def step(self,action):\n",
    "        target = self.out_data[self.idx,self.mode]\n",
    "\n",
    "        if action in self._a_list:\n",
    "            raise Exception(\"{} already in list\".format(action))\n",
    "\n",
    "        self._a_list.append(action)\n",
    "            \n",
    "        if target==action:\n",
    "            reward = 1\n",
    "            \n",
    "            if self.mode == 0:\n",
    "                self.state[3+action]=1\n",
    "            else:\n",
    "                self.state[3+len(p1)+action]=1\n",
    "                \n",
    "            self.mode += 1\n",
    "            self._a_list = []\n",
    "            terminal = True if self.mode > 1 else False\n",
    "            \n",
    "        else:\n",
    "            reward = -1\n",
    "            terminal = False\n",
    "        \n",
    "        return self.state, reward, terminal\n",
    "    \n",
    "    def avail(self):\n",
    "        a_list = np.array(self._a_list)\n",
    "        a_range = np.arange(*self.action_shape)\n",
    "        a_avail = np.where(np.isin(a_range,a_list),0,1)\n",
    "        return  a_avail\n",
    "    \n",
    "    def sample(self):\n",
    "        \n",
    "        a_avail = self.avail()\n",
    "        tot = a_avail.sum()\n",
    "        a_prob = a_avail/tot if tot > 0 else a_avail\n",
    "\n",
    "        return np.random.choice(len(a_prob),p=a_prob)\n",
    "    \n",
    "    def index(self,x):\n",
    "        self.idx=x\n",
    "        \n",
    "    def inc(self):\n",
    "        self.idx += 1\n",
    "        self.idx %= self.l\n",
    "    \n",
    "    def mask(self):\n",
    "        \n",
    "        return self.avail()\n",
    "\n",
    "train_env=CustomerEnv(dataset)\n",
    "test_env=CustomerEnv(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn=DQN([train_env,test_env],\n",
    "        model,\n",
    "        gamma=0.5,\n",
    "        optimizer=rm.Adam(lr=0.01),\n",
    "        action_filter=EpsilonSLFilter(epsilon_step=20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0001 epsilon 0.9984 loss 0.4725 rewards in epoch -14.000 episode 0004 rewards in episode -4.000.:   0%|          | 33/22000 [00:00<01:48, 201.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run random 0 step for storing experiences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 001 avg_loss:0.1467 total reward in epoch: [train:-2999.000 test: 2.0] avg train reward in episode:-0.631 epsilon :0.000: 100%|██████████| 22000/22000 [02:56<00:00, 124.40it/s]\n"
     ]
    }
   ],
   "source": [
    "dqn.fit(epoch=1,epoch_step=22000,random_step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Result\n",
    "\n",
    "Here we show the reward for each epsiode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzsnXeYFdXZwH9nl11670oX6b0JYsEKGlTUWBMbxhqjJuoXjcYYg13RaIxoojGJDSwoErAgrBWkKCIdlKVIE5Bld2Fhy/n+mDt3586dfue23fN7nvvcuTOnzbkz73vOe855j5BSolAoFAoFQE66C6BQKBSKzEEpBYVCoVBEUUpBoVAoFFGUUlAoFApFFKUUFAqFQhFFKQWFQqFQRFFKQaFQKBRRlFJQKBQKRZS0KgUhREchxDwhxEohxAohxE3pLI9CoVDUdkQ6VzQLIdoD7aWUXwkhGgNLgAlSypV2cZo1aya7d++esjJmC6WlpTRs2DDdxchIVN1Yo+rFnppYN0uWLNklpWztFq5OKgpjh5RyG7AtclwshFgFHA7YKoW2bduyePFiAHbvhk2boH17KC2F8nLo3h2Ki6GkBPLzoW5d+OEHaNhQC7NnD+zaBX37ghDQuDFUVUHz5lCnjha2vBzq1YNWrWDvXqhfHxYvhmbNtHOVldChAyxaBCNHQlkZ/PSTVr6OHbX0Dx2Cd97RytazJ+TlQW4u6Dq4a1ct/0OHYMcOLb/166FLFy3OokVQUaGl1amTFq5dOzhwQCvrtm3a7yZNYNYsOHDgSzp2PIpOneDgQa1M27bB99/DgAGwYYMWd9w4rRxz50Lv3lBUBDt3wuGHwyefwMCBWv21bAl9+mhl69wZ9u3Tzs+apZW9tFSLe/HF2r3v3g2HHQZr1mjlAi1Op05QWKjVS3ExrFsHbdtqdSolbNwIw4ZpeeflweDBWvlbtdL+v/Jy2LxZC9+woVYvDRpAt27w449avRQVwYgRWlghYMoU6NcPmjaFCRPghRcWM2zYMBo1gnnz4LjjtPI3b66l/ckn2j2tWaP9B2PHankXF2vl3rpVOx4yRPvvc3O1/6uoCBo1gtatYflyOPZY+OADrQzaM6199+mjPT/HH69d37cPhg/X6q24WLu30lIYNAhmzNDuvbxcq4fiYjjhBO37iy+0umvaVEvjmGO0sun1P3iwdg/bt2thGjbU3o/8fO25Au3+zjhD+x/btv2aOnUGU1io1f3hh2t1ov9fp58OH36ovQPFxVoebdtq91VWppWve3dYtUq7PmIErFihPS9HHQX//Kf2PnXoAKedptVZRYWWXoMG2n9x5JHV6efnwymnaHVVWKg9F/qzuGmT9mnRQju/aFH1fb38MowapT0L3btr/8vJJ2v/a0mJVkdHHKH9L6WlWt1t3qy9lwcOaPd02GFa2fPzYcsW+PbbnRx9dBtKS7U8mzfX/vfdu7V6Xb1a+58OHNDqo6ICevXSfn/3HfTvXy136teHNm20dHNztfy2bdPOFxZq8YqKtDwGDoSCAq1e1q+HnByt3kpLNblQWAiffqo9rw0aaO9nw4ZaHTVooIVduVIL27Klls7XX2tyYskSsdGrYM6ID9AF2AQ0sbh2NbAYWNy6dWs5b948OW/ePKn9HbGfs87aYnne7TN06O64uEccUewa75RTtsnDDtsf/T1nToGn/G65ZbWcN2+eHDdua9y1adO+8Fzuzp1LAt2v+qiP+tS2D4s9yeJ0K4OI0G+EZjo6xy1sjx49pI7VjXfrFrzSgsStXz/294ED3uJNnKjdQ6tW8dcWL07ng6M+6qM+NfPjTSmkffaRECIPeBN4WUr5VrrLkyqkTHcJFIrsohU/kktFwuk0ZS/1OBBCiVJDS3ZRh3LTWUlbtnuK35lCwLvASffsIwE8D6ySUk5OZ1mCooS7QpF8GrOPH2nDZH6XcFp7ac7XDA6hVMknh0p20Zp/8quY8//Hw2ynPV353jH+SOZTSFcu50UfeaaX0cAlwIlCiKWRz+lpLpMvzEpBKQmFInyaUgTA2UwPJb1erAklnWSTF+khXMSrMefH8j4AXdngGP9I1gFwAvM855nu2UefASKdZUiUoEpAKQ9FbSaXChpTzF6aA9CQEg5QnypyLcOLiPlDIgBJY4oppomv/OpykP04TzPN5yACyUHqxZxvQCkHqUsldWKOjbTiR4ppHBe3PvspJ488yiknjwrybPPXw4KmCMsiaQmD+UdQRf2I+SuXSsf7qYiUsY4Ps1u6ewoZhQhBPfkV9lbhwyiHQpHJPMfV/Ig2ZT6HSkpozN+53ja8LhSryOFGnmQfTenIJs/5vcLFlNLINdyPtKaIpnHnS2nEK1wcPX6bCabyVfEjbSijflzc/TTkE45jPw15n7GO+e+nIR9zPM9zJbtoTV0ORtKvFhT3cA+jWAC4C3tdKeTFjUnYU+OUQqpb4EEFuOopKGozE/kXdSKtXF2wXcG/bMPnUAVoPYVzeRNwN50YOZ/XPYVrQjF1OeSaxnj+F3Mt3yaOji7ET/Rgxjma+VzKfwFoSGnc9QuYGj126ylURUS8yJaB5ppAomMKqlegACxml2QGqSiXLtiqHMSR0XwUa0ryS3JaY0alIKgKZZYUQAP2x52rMJit3JSCXke6UvVCjVMK6Rayqgeg8MtRLKCcfE7ko3QXJYYzmEE5+Qzgm6Tmo/cUnIS80XyUiFLwY0apzrtaoNoJe6NS+BdXOI4b+EFXCsaWfrkhbTfzkeopKBRZyPF8DMCpfJDmksRyBu8CMIKFSc1HF2xOPQWj+UgX7OUBBK+fFrO5fEDUxm/GqBQu4z++87DDSin46SnodVqrewqpRk1JVYSFn9ZcKvBTHs3MFKT80ldPwagUKm1mKjlhJRzrW5hojPhVCrEk9p/qSiEnQaVQqweaU01QpaCHU0pEETZjmIdExJl9LuRVJILD2RJ6nuvpzl/x7/leIKNz6BtFBlUbUoJEcAuPRsPpws+oFKyUlkQ4Khezjb4f37KfhjF5menF6uixH6UwgG+wchoxm3FUmBTa80y0LPcxfBY9lgha8WOMUvA61fR0ZnsKB0opJIx5DEMJeYVfgg2Y2qMv8BpDQcz5K3kegN6sCjU/gM5s4kae8h0vhyrG8V7MuTbsBODXPB09Z1QKugAO0rNqwr6Y34exFYAzmWEbZ2Rk5hBAPcosw1gpBXP964zjfXJNPZaJNjOv6pvccXRlQ4yZza2n4HbdihqnFFItlBPtKSgUqUIXEEHMLskih6o44W5VTr9KQdjY0M0taz0Nry1uPz2FMMyBZrNPFTkxjQi3cgcZQ6lxSiER0rF4zSrPdM+gqq0MY5Gl2SUoazmS2YyLObeannHnHub3QKwQeY0L2E7b6O9D5PF3rvOUr13PIxVKQSL4BS/ZXruHP8WcO0RdLuff0d8t2cU6esSVs13E+VsdKqKCcgGjouaiHFOL2M6GbhSizzOR9zjNMnx+RPgfx8f8nV9Hz9sphTc5N+7cE/zWMqyRB/m9Y0/xZv4a87s+BzieT6K/3XoCSimkAdXirznoZpefmRYmBeVI1jMu4qNGpydr485ZcQHTaBsxowDkUcF1TPGUr1sL1au5KqhZ62aesL32J+61vbaAo+hp8ElkVAr6Pf1Ec0uBbxbWdgO/RiFqNNmYW9y6ryWzzyE7pdCVQsvzZnbRMub373nYUzyd1vwY81spBQ+ku5WtlET2ogvBTJsFFDbJvj9rk4Z7nmXUi7GXG4/1NEtoZCnwzXnaKQU7c4tZ0ejC1jjt9RB5tkrBK3toYXm+3KMbOvO0XTfzkX4f+y3cb9hR45RCugnD95EiPZiVwkx+xgec4jqjJRHesDA7GGlsGhi1wli+9xgbHfAdxfzotabs9aT0zuUNJMImX4lEcJOhJ3ASc+LqJo9yXufnfMox0XNeFJFExPQOrJRCFTmWAv9aUy/qPF5HIjiNWTHnv2aIZd5mpbCNw+jNSg5SN3oun3I+5bjo7zmcRDGNfD0bPSJeSyG2J2bMx4m3OTvmt9eegp8yKqWQIGqgueZgFpo/YxanMCepeZ6L875SbQwmJC+MNSyAu9DgI6cnazwJhrsj5p0uFuYQXcAYbeW/sZhxJJD8nDc5hs/j4rphVARGBWFcm2BlPrqXu2N+Px0ZB7iFxzzla6W0zuEtljLINs5JzI1Oo/XKDtpYnj9Evq90dNRAcxaghH32k0nmIz8uj50wKgSn+3MajK72UVSdllU4K0HkRTiZewrGY70eKskl30IpmFvMustpr/VnVSd1qLAV1l7NPWbsBvmDKgU1phDh9tvtxw6+d96IyJH16/3HqTLVeRvrhkAcL72k3cPu3fHXhlj3cGss3VlHJTn0NCwSSoSPOQ6JYArXeAq/il7cwqP8kUkANKKEdxlvG34+I+Nm0YRBtWCqFlCr6c1I5luG/4rB3MVfPKfvxXxknPppLpfVtXMsNr3RB2n1sF8xOFBPYRhLALiA13g14rbabhFWHhWRbSc1dNu915W8VnXyC15mGhdYhg/iYgPshXRFQCWjlEKEhx5KdwkUYXIxr5CDjJvpEZTj+BSAa3jOU/herOFRbov+PoLv4lwjGxnJl46zaBLFLKDsTCCDWcpfTGYTI5WG19s47uCkFHR7fQ5VcX5zrJSCFe1NewcPZqkn4ZTPIcuyPe5haifABN6OHs/gTMC7ULTK90jsW4lOfpqcCFspuN2f1/8sNk2FIs3oD3bQFy1skjWo7BXzi+69tWcv7L0OlusrdgUy+n/ogiXI6lgdL/dQnwOW4fbTwFMeVuXzagpMlcnQrg6TpRTUQLMiKzmaL4DkKoX2bGUr7elhmAefz0HWcqSvdNycp9nxISdzo2kh0oORRWtmzC+6lYnGCrPAMbpSsBtTaM9WttM2arrTp1zmUBW1f5uVgkTwOx6LW4TnhPGe5nKCZZihfBV3D59wLEe4bE6vY4w7nEUAHMXCpCj5oGM9dkI8qDnqHv7MNtpFZ4Tpyn8HbejPstpjPlLULHRlsJpeScvj57xBe7bH+NPpwBZLE4HToF/PgBu+n8xH/JWbY87ZLVwK8iK7xSujXlQ4GoXnObxFW3ZyA3+LuSYi00+NGJXCY9xquwjvFS5yLNsJNj6BzGUDONbgEM4No7IbEVEKQeJ6wVzOfTQOFE9nE5185W+kHTviVk+34Ud+x2SlFBTZiS58kmm2sfIrb9c6c2oFpsJvUDKUQg5Vlrtw2e3MZfRJpIfx4uIaiO697LVsQcJZEWQDHR2/SsEc3uqerbC7v0TKbkcVOcohniI45zOV6abNyL1yDm/yDmfSiY0sZSBt2OErvi6wg3bJBVV8xImc6uA+Qs9jAMui54J02a0EYnfW8TWDaIHFVDIberPS9loylMLZBhOUUVDYDT6LiCHCeE2PZ7eHsVM59pjcO9jxC172FM6KSfwxcFy/SsF8j16Fup2QNntDDcIgvo75XUUOR0YWy6kxBYVvpnIhE3gnUNw3+Tln8i438iQDWcYvbRyi2WFuifqlMcWcyDxe5zzbMIV0AWJNQ3ZjGP/jZ7bplNIw7tztPMggvomZ/eKGebEVVAumZCiFe/mTpfnIrBSMZTCXx2urM5EB6V/z98BxE8G/UogN71Up2P1H+RxiJb19lcHMI4YZdKA930U0BYh+e0EpBUVoBBUGiSoFPz6LjC9lMHtrcPOG13Tsru228Zuj43UTd2M4u+0ajT0Fv0ohrAV3P3BYKOl4IdHZR4n2FOpQQRFNmenQIHHDPIOpipzof6f2aM5AfsOT/B+Zv8DCbmNyL+gzVySCO5nE1TzrKZ4umF5gou88h7MwOiddIKln0w3XBZXxpbR7UbwKbIlgJb25khcc0zN36+3y0O3+e2lum79OvoVjNjeFpbvAMIYbwleAJtSuYQpNIz6PrHoKb3GOa7kgsZ6CkVRPDf6KwYHjelUKdRyUQhU5Cc3AMw/8n8ub0f9O7dGcgTzJTTzE7ekuhiuJvNBGR2WT+CPPcq2neNWDnf5ba49xC2MiG9/nUMVxBl/zRqwGSe2EuFMdmF+u3oZV2HbpTeIu13TA3c+RsexH8aWnNK0w3p++wK8765li2K/BqqcwyOM+E2EphUQE5Hd08xVeIBnM0sD52e/R7I08yhNWCmZas0spBUXiJNKNDvpiJPIiNKY4euxUdqvN3hPtKdjlYcZqC0erdPzMbArqXwi8LfKK7yl4fy4yQSn4nSWWKvORHWH0FKxQ5iMFABOYHuPeWEMymd8yJOJPxo56lCERnO3gvfM8pnG9Yb6/jq4U7ja5gLiLv3AyH0bL8QQ3MdDQKgvLTGAlFLuzjme4Nmra0oXF73mQLXS0TMdOqF3H3x0Fnp1StHohrdJxE+qt2I1EMIxFUS+gbmlaoedjXIhn9Giql9moFM7gXU9pA1zic6KBHV3YGDiu33GNwyN7NQfPLzFFmIyeAsBtPAr46ykEW1utyGimR2y/xsVS9TnAb3mC63iG+jabj0P1BuZvca5t60J3EvZ3k2DSW0vNDA7RgKh/HoGkGXu5iSe5jH/TnL1AuErBXOZpnM9glka9ZupK4UHucEzHir/z6xhlZsZuA5ZjI76Y3PLwuoHLIkZYnvcqCHXlcQn/tQ1j7inM4CxPaaeDcuqQZ7r3sHorqSJZPQUdZT5SxKEL7HougifZ/m10jCaVsJSCUxfZjw+YoOYju56CWWDZpZOoXdpNKSxmKBC7atkOgQxkj04HVqaisGZABcHOjYcTdahAIhyVwoFIwyYIqqegADSXw1Xk8CGn8KzBjfRwFkZbm3kcYjK/i14zKoUcKqkyvHCX8SI/OcyM8fLg6ekblVPsiyAhoJKwEnJtIwvp9LKdzmxO5CNPZbTiUv5je02fyaOVxbkurDbvSdQu7RZfV4g38iRX8xwjLQardS7nxeixH9NROtCmYsY2dtKpFLzuomYkk3oKSinUYF6L+KD5KzdyPq9Hzy/kqKgAncDb3GAYHzC+TMfxCQWGVs+LXOGYn5dehtXLap4RFLTnYBX3MLbFle0jTnZMx+kF+q3DpvRnGxavBelxhTGDxQm9brzMIrqCF/k3lwIwnMUJlSvZWHkYTadSOOBjP2SdBuzPGKWgzEe1ACcBZRYkxpcp0aX/Vli9rMZ8EjFVSIRtfD9COgx7dJD7SLZS8Eu67PKVPsWSVSMinUqh2KNzPCN1OeSqFBIxs2bV7CMhxDghxBohxHohRNIn8guqmMSdtDVtBJIOmlDEQ/wfeR6FwQC+sZhVlBhm4aV7y4TUKQWj8DnLxtXGpfybe/gTv4jMbGlICQ9zW8zYRC5VNKLEMv7V/MO1bDo38qTnsFYMY1FMPXrlOIsBaT+MZ6bjdb+eQ41+olKJ39ay3Vaa6aKERoHiZUpPASll2j5ALvAd0A3IB74B+jjF6dGjh9R2Qg72OY4CKUHO5PSE0vH70Q+M557kBilBXsHzgdNwCqd/9HyMH/3wEv5tm9CJzHFM13z+Q06yCFMVE/4I1kkJsoKcaLC3mGCZrl3eIOX93G5Z5s8Zlbo/1eJjVU/q4+9zgLq+wu+lSdy5g+SlrfwP8PtA8d7hDPk8V9heL6V+QnUKLPYil9PdUxgBrJdSfi+lPAS8Bsmd+6ZrzAYBN0sJE30KYjLc5nolTFcCXhZUWa0sDtP+Hoa3SUV6yfaegpXTRC9kSk8h3QPNhwObDb+3AEclM0Pdk2WqptmN5T3aRwY7zXh15HYCc01KTGKeoXMOb7KTNnzGsbb5WGFnrgHozSqO5gvu5w8xs5B0/sB9PGCY729Vp+aXs1lkbUIdKhnMV3zNEAtnbFWMYj7t2M4mOtHdtBFON75jsIU/Iav8FNlHgxAUexCXKWER1HzkdcvUIOT7aHimWyl4QghxNXA1QOvW3jazsOOmBO3FfnmP02yveVUKczkp5vdwFsUtYHqTn3tKy8zPedP22t/4DQDL6cfbnB13/T7uYklk7jtYKwVzL6AhpdHjrxiKQMaFOY3Z/I/xtuX6hONsV6Cms9f1PqemLe/aTKr2V/ZKIj2FdO8PDukfaP4BYnwNdIici0FK+ZyUcpiUcljz5u4eJL2Qih203PDj8tlIqgWf00pboxnH6oE2C3wvisNtFk5rfrS9ls6ewnL6pS1vReaQLKWQKoWRbqWwCDhSCNFVCJEPXAgRPwtJxqgUjqeAY228a1rxK/5BewdfKRN5nmEOMz0u5mVG8QXXMQWAjmzmioj7ZS/4VSJdKIw7t5Yjbd1Mmzk8Xk9blsVNKVSQa7kRjl9TnlNXuDvf+UorTDJ95W9NJdN6CvtpYHm+ykWou40npOo+06oUpJQVwA3A+8AqYJqUckUq8jYqhQJO4BOO9xSvLdv5B1c77s71PL9itoPZ6GV+yReMjv6+gwd5gStpHPFl74Zf4XOmxYrUI1nPa1zoKf5j3Gp7zU0pGFvuuVTF+UWC+PvJhC50ELLN304qmGJYSZ8sMk0ZV5LLGnrEnXd7ru16Cl8aTMWzOI0H+X3ihXQg3T0FpJSzpJQ9pJRHSCnvS1W+Qc1H+ovf1mUf4lY+9us1p+1GWC9BywBlNOOnp2BHpr3UQQl6H24tyGzlNh7mW/qHktarDg0YieBmHg8lHy/c67IXdBU59GJN3PmgSuFh/i8a/2fM4g4edEznGqawhCGOYZxIu1JIBsfxseVuV0aCKoWg4wBe8JqmWfi43asdflrk10RMXWauNZy36v4ew2eO6Y7n3ejm4tlOB7ZwPlN9x0vnTJlkUkWO7WJCv2RS79GLcA8STyIsZYCVGw83hhr8cPklK2Yf+eVjxgDOQjaoINL/8OBKwT6e15amOdzXAVsFfuZEG3flMqJv8WhVLqieFWXHu5GtNI3so4nncmUSE3iHCQ5TfJPBxxzH8T7Gw1KJRMQ41kuETLG3e8GurG73UEUOXdkQc24b7diawr2qoYb2FLxgtRuWF+w2OveKm7tiL4Rlbgm79RXWrKhy8kJJpzZwIa9xkoXHVR2BZH8AB21hUEWO40wxM39Asx7PZ6RlWpkk+HUu5uXo8Qr6APFWiN9HzD1eehjGd/t5JnIY29hDi7CK64laqxSC23+dlcIFvBY9Hm8xwOv0YLdjOxOYDsBveJJzecMyXC6VdGKjqwtoN/S9jcMiLKWgBmy9U0muaws0XaYXifA1RdjJpOt2D6lUGMayGBswehnM/4dXU7VZ8ZnTqy1TUtPGIoYnFN9KKRzDp1F31WBtGnF6eL9lANM5hw5s5klu4g2L6Zt63mvp4eoCOtWEpRRqysCzV+7g/sBxK6hjqxT0TXXSaY9/khs9hZvCNVHhafWOJMv9Q6JY2fvNZfUq1M1KYSL/AqyVymY6ANrUcjNzOdGl1M5kZk2ngKB2Ov1Ps3pwm1pMt7SL74SbaSuHKuom6GY5GdSEnoJuAkglTluDulFBHduWaCbsg/BWZGtYN2ZwZowwfTKyml7Hj1LYZLP3dlj47Snov72MKXhViJ3YjEDSk7Vx19ZbKAo/1FqlYI1kAtPpzrqYGT2j+CJusVoulUxgOvkc5EzeAQt3DVZ4aQUblcJkfht33Woxms5pzHJNP1mEtZo4nUohE1a6+yXd5iOn/Q/8mHWcegpOYxPmWTup7FVYKQXzMxS0p6CT6mey1isF44KxC5jKdM5hHT1iZvR8wWhW0Beo/uObUMx0zmE3LXmHCYzlfW7hMdf8vCiFx7glemy109dThi754WyJuTbLYVFdsqkJPYVsUwoHqJ92pfAIt1me92vnd6p7qwWYdoSlFBbY+Ob021PQw7v9Dx0jrX8zqTad1XqlYBTS7Rw23mke8e5p/tMaRRy8tWIXndnomp+X1rSf6bJGB3PppiaMKWSCUtBnC43mM37LZMewFeSlVClYmWYe57eWPVoR8fvpBYEMLPzM+Vj9h4c5uGqxYxQLXFvuYY4p1KPMMT810BwiPVhDZxuTi58HsRU/2j7kXv+wE5nrGsaPGSaTBmWV+SgcDpEPaM+ml7pI9yCs0wwoP0rByXzkB6uyhFlHxrT8jCm4yYgK6liOJ6qeQhJYQy8K6RpzzmrA2O1PW8wwR6Xg5WF+hwmuYfy0uDNJKdQE81EqX8ASGrKeIxzLsphhrum4KbJktzArqGOZRyLmo3c5w3M8c97m//B9Tg21Dj4yuLL3Yz5q6uLbrII6HMXCuPNqTCHF+FEKndlke82rUvCCnw3cc6iKcZiVTmqjUthAF8frt/KI7bVm7LU0FerPYRU5rKaXaxmSaT66jz+4hqkkN5rHJO7kr4Yxr6Dmozmc4qucduYjQRXjeC9UZb+IEfwQmb1otdDSbqDZDTt3Fm5jElbTUhOhRrq5sKNpZFwAqjclN7a0vbw8ifYUvOBHuOZSmTErPcNSCuncE8Gv8Djgslr4IHVtr1W6vH5eN11JplLwsrrcuI1kJbkxZqCwZh/5IbY+vA3yBs3Dj/nIDbvGkFt9hN2TqFU9hS84Onp8PJ+QYxKoVg+OeSqq3R8U5jJ8Pz2F63imximFdO6eZvUCH6CebXg3Z2WJuOzIFqWgj4HoZWnOTwC0YA+bfawZSGSg+XODK/pkjynoeYK1QA6qFMbzvxhzYlHEB5je8Pgnv7KM918uAWAjnWzTnsSdnsoAtUwp9GFV3Dk3paA/4FbhjYTZU/CzMK0XqzNGKYTVwvejFMPG6gX+ysHhYFhKoZDOlmXxIlCMgsnNnOUXo8C/mz9H35EzeYcmFNGcPVQY7rGKHAojZagklx20o4HHGXKJtHjnc3R0vYRVnSVrXCXWVBXbU6jPfhqzz1fePVgbdY+zit4AlJNPffZzK49axnmAO6jPfo7gO+raLHz9I5M8lyHrzEf79oXnLO0wtjp275uyN65LZyeAG1HCYWwLrWxekQhPU2HDogph6+q5TkhjAelUCn4Fk9sL71UpWKUTpKdgZc4Kq6dQSW70+S+lIcUGb7ZGgaj39PS6PGCzE5mRRGYf6fdXSkOaUJy2noL5XFnkv/CTtySH3bSMHFf/b2WOZkoRve5mkvRC1vUUtm+378r7ZTOdHHsKyxjgufX7LyaGVq6FPvwyfcUQWrMrtLzdSIXv/0wzHzkJKTe/9UcwFQkfAAAgAElEQVR43B70bYtZaUGUQrKEH8CXhsVc5nyMSkFvSPlVsImW3ThAb3dN53UXl+6HDMrQqhenY7xHuwHhdE8Z3ktTX+GzTin4x1mIOSmFTmz23FMIEysBYcd8RiWxJP7ZSCce5+aE0sgU89HTXJ9wes0MkxuceJDbASimUUxZvCgFYxgrQey3p9CcPdFj/flfysAYB4x2aQZVCmGsU3C6T7NgvphXOJ3/WYZ9nJtj/rderKYRxXHlNaer99LMjZp0OCSsz346U0gjimnv04KRdeYjv7hNb3SbfdSP5TG/U6EU/EzJzDQ308U0dp2R40YqzWFmjC/5dtolnJ7XujDma2zx+hUoYdjT99I8eqw/77oDSbvWuB5OIgL3FJI5H99cBxXkUWTTgt5PgxiT10HqcdAmXSul0ID9tmG8EIaMKaM+mxx6OE7U+J6Cm/nneMOeAlYC1mwWUkrBGeOcdT/sithRAX7N38Mski+MZQ+yDaIZrz05q1WvMjKpM1ESSUN/3vW6sJt2aWRhZN3M1wy2DfOFqV6+p5tjmmvo4VpWp61ywzbhzIi4xS8x9Oz0BXc/0toy7x208ZVHulye13ql0NswIymd8+ON+FUKydj4/WsGWZ538ogJwVq3oLlYHpzAvrJhYRQeQZVCH1ZEjz/gVN/56r3XcpNfozbs4GQ+jItrfF7CbrToZTHXhZOQfYPz6Eyh7QK00XwWs01nJzaynP6O5qNJ3OVaVvNWub/kv9FrYQvY3/AUh/EDxTShDytowW4mcRcd2RTnPUHP+zuH1etG0j2bsMYrBTcB6/eFSsUgqB+l0J5tFNM49DKstWmZefEJH+QFrCKHDaaXKR1YKQW/L+kqw54MXk0ixkFKoyA21uWPtInOTDFibMxYuT0JQyCaZ1GZ0zSajwBH08V22lFmWPuxOTK/3unZ8vIfmHsKxhZ72D2FCvLYFjGpraIPP9ECSQ5bLNZlpHug2S/ZVdoAuLX+7/S569UUrk2kOJ7woxQe4nZXnypBsBNmeS71GdR81IXCjHBGZ3yBdeHidbDYiD7jw+qeDhrm/ptxUgpmPuFYAH4yjAEM4FvfZXViPd2BajOY0wwf43UnBNIynNP//z3dXNPV0evPbIozo48Zvct4AMocpqcnglIKGYYfh3Fewp7kwctpoqR6nGB5ZK8Ina58H/hBDtpT6MCWpCqFoR53ITPet96g2MphPMjvPcWfzThAU3Lt2WpZj+3YTjuHGSFelcJpzAZgO+35N5fahkukpzCfUfRmJX/lJsB+TMGtJd+BzVGbup2bbDvzUX+W8TnHuJZVv0/9/THet1V+33MEPVnNBN6mJ6u534OfpyA41X9nCnmOq3zHSyZKKQQMm0xSrRT2GRYhARTSNbBSCNpT8Lp614yXrRcL6cxXDHV0V2Esh5kSGrElsieuG7rJoohmbKc9WNTFXpqzw2Fmk3Fw16ku99MwerzCpNiNJCJcKqjDanqj34f+jvjtKfxAh+hsH2NPocjw7Olpmt9Dp3uzytuqjPbO5HpSRW7kOzni0CndTXSOM/+qMYUk46eC0/1n6KRaKRzN/LhzQV+Qo/iSVgEW0w3g20A9hU84DoCfaGYbxsuMGR07XzZen41LDYObftDdSRQwJqan4PV/WGfylFlhsajKic8NfsGMmOujQ2SzmsY28/ad+CzS2i+mseVsqzbsBGBgxFmljvRYBx9zPABzIuspjGMK6Wp1Q/wAuBm78TvVU0gSfgR9be0pWBH0gUzE1YVfpdCfZfyKf9KN7+jO+phrw1gUPfajFFLhIsGKAzSgL8u5mFc8m4+MfGYwr3Rhg68FSx3ZxDje41Tep61p90G7/6QpRTG/zQPNVlzHMwzgG7bT3jLc4QF2R4PqCQGX8h/68S238yDH8CnfMiCmhOnC7T98n7FAda833Y3TGrZ4TcYNLNdU89FB8n05zvNLIoIwqFLzq4iW0x+ADRaDkEsMm9O4mTyM2C3+SsWLujJiJrGbBuqEse42mpziudWrPmPmQ8P02QpyqUOlrVIIMtB8iLpRQW3VUwj6zOn1VEZ9VtAPwNMYhJlktcy97ryWzt6MkRrVU3iK31BumtmRjT0FL/5ykqkQILEH1GzK8E5yXopElUKqZ4/oLt6txmf22pjJwhYo5kVrZvwONJuxKm/Qe8g0Vy9m3MxHpZGxoUURn2e7aAXANwxMQeniqVFK4QaejjtXU5VCsklEED7BzTzKLSGWphq7RXWg7cVtZCLPA8GVgtEk4vU5uoc/eQrnxHhmMpTFSIuZXIV05VqeiduIXg9ntbjQquwnMcexDLmROrPrKbitU3DDynmcn2euL8vpwGZG8CUX8aqnOOlaHOl2X7tozVEs4FL+A8BqejOaz/gdk1NRvDhqlFKwwo+gT7ctTycTyuHlBbWbby/JYS4nhl0kIN6FgJF1pgE7fR66H4FltbLYj7DaRnvPYe3YR1O+YihgXeZnuTa6cErHyURh9TzpA/RuhGk+csNPPa+lBz/QgUWMoNTgasKJpQ5uN5KJlzpZyFEx/pa+YDSHkrRuwg1Xo6UQ4hyn61LKt8IrTmJY+fr3I2DvDaGVFwaZsNjFr3dOM8m6h/0efPPr6KYPP8LduGJdV0Dr6R51COeGXR4HqEd9mw1QnEik5a1j1TByq4slDGEoX3lWCmN5H4C+BhcfTlgpaj8OCDPhHfFKNpUVvPUUzoh8rgSeB34R+fwTQtxEIAS8vhCZjtPGP37ZZeEWwQtWD/IFvBbz20nhGoWJvqArDPQ1Fe978Cmkl8FNKTzMbdFj41TLjziJ05jFvdzNG/ycnzEzeq0/y+jChri0rGzww1iUgEnQn1Kwukf9/q/kn7TiR47mc1dlcwofcgyf2uZvzqdXxHQ3hgJP5TWXG2AeJwBQYlh/4SVepuM2ppBpuCoFKeUVUsorgDygj5TyXCnluUDfyLmMwesGKfMZmYriBCYsx3zPcjUf2jglc8OqLqdxfsxvL0qhlAYx++ea+dDgo98PdgOuRrx69jRO5zQ3It7jtMh2k4JZ/Cx6fjn942b5gLW5ZQnD4sw9YeNFKcxkPLtpxXyOdhWqP9HCcQaPXfz6HPBUXqdnx8tuddmkFLKprOBvTKGjlNI4+XkHOOwU7YIQ4hEhxGohxDIhxHQhhPtbHuEVLkJ3K9yGHdHzVpX/XcR3i5FM786F5XQvEdfL1vFizzmZVIyt9OptCuPrPagTPC/3Ze4prKaXZTij76BSQyvVS8tuv2m/hHQ9W17MR7G9mMQElXkVvM4O2nqKrwt+43+il28NPQE3X0ThC9pkteT1+g+6DiPV+HmCPxJCvC+EuFwIcTnwP3CZwuDMh0A/KeUAYC1wh9eIFxnMGP0NDsC8vpDJ9LHjpeurcyuPWJ5Ppwtv3UTkVpclNOQBh7/MahaPVZr3cjcQu+OYma8ZxE7TALMXpWDuKZzLmzEmIB1jT2F5ZJ67HZ0pjJhVNHqyhuMMe3Kku8Hh1FMIo2xd2MDTXM9i05ax8xgDwB/5i6d0imjGacziTGZEz5XQmHHM5meRHdF6sDambsPgKBbQnXWB4g5kKf0COBzUx6aMZuFRfEG3DJhlaIXnp0RKeQMwBRgY+TwnpfxN0IyllB9IKXXptwA8OpdxStNj6yGZSmEFfWP8uTgxnbMtzydLKXzmYMYBTTBP4wLAvS5f5zxHIWO0ozrN/tFdKDu10lbSh68YEnMuSE9hL81jTEDViLg4dmXaROcYs8oWOvKpYSZPuuzGVp5BdfxOF3ViI10sp37r+BkPe4/T+IkWMefeZxx7IuNgm+kUU7dhsJCjLK0H4F4/yxgYXRznB/0ZN5omFzDKctFlJuBpyaQQIheYI6U8AZiehHJMBKZ6CWiei64/8Mvp63l2RyNK/JXOB35MNnZCtb3J1UAi+BFSGw0+8K+MzPG3o4ocx0F8473ppoZ8C7OY7vPHyYy0nXZRYfMDh0fPuWFWCl4w/neHHFxc25GMvS28oN+rlYvpDXRlEN+EspOcG9lmP08F5llwmY6np0RKWSmEqBJCNJVSFrnH0BBCzAHLt/dOKeU7kTB3AhXAyw7pXA1cDURmb8fTl5Vei0VXw6yRb+lHf9M+zIkgEQmZsbZweNTpWBjoSuFWHuFsG33egzWspSfDDO6lm5gcnuk8yO+5nYfYR5PoQ76LlrRid0w4Y0/hX1xBDlU8xq0ArKAPz3MlG+hKMU04m7dsV6VWkMud3EcdKpjHCbzEL1lLD17lItd7D7pJDmieVa02THFD35IxlVxwwSamTu3EObxpOag/lvcZzeee5/MHIVtm1qSDII0TM8cfv5N27cpYsaIpLVse5OOP/W3t6Qc/TYcS4FshxIdAqX5SSnmjXQQppePUksjYxHjgJCml7VMlpXwOeA5gmBBx4YTPyjYK4zIP7pT94EcpWIXbRKekKAUn18/r6OH5pdbto8aewjTO53qeiQlnVApFNGMyt0SVwm5a8ji/i4Z928aMBvAvrohunP4SlwDwIld4KmsiPYXXOc9znFhS31K+4YZOTJ0K07FeUrSTtrbXwiJME1WijB8PM+OHjtKG/hwm4uiyoCBWCYgkVrMfpfBW5BMKQohxwP8Bx0sp9wdOB2lb2X1tegBGpTDc4+YrfvAqhKx6Cp3ZGGpZwn5ZjbZrpwFMJ8Xox+4cRrk1leIvP78t3300tu1d1QZ2RjbQOWCajZVN6Ps96N9hEUZPIZX4GWj+t9Ungbz/BjQGPhRCLBVCTAmakJ1SMG4ObiSZA80SEedW2I4qcjjDMPsC4HC2hlYW4yCv3Y5oE2xMSk9xg22aEK8UTuGDmHBWC3Zu4VHA2VWFzlTTmgivnMXb9I6YEhtg3dY4mQ9jXGsbCaoUBrGU870Ni9VIruIfXMMUFjIi3UUJzBSu5Ub+yhPcHGq6xs2DxvIeg/g61PTDxnNPQQhxJPAA0AeqbS5SykBD6FJK6ykAPnHqKdgNrCVzwE0ios7E3Kgih08j++wmA20vM/tZKQDvMMHyvN2euHZKYY5pkZxVT0Ff1+ClxeRnT14jMzgremx3zx85LJgL2jPZQLeMnU2SCopoxnNck+5iJEQldXgKW2t4YPR3IZdKPojsnZDJ+Jm4/C/gGbRB4ROA/wAvJaNQfqhDhe3ORbfzkOX5ZCsFrwTdutIrxoVjfvcEsCuXMT3dVGC1kMmqp+BnuX8YA5eJ/M/ZNHCaTPtyNpJp9aEv1DMuksxk/CiF+lLKjwAhpdwopbwHLCd9p5Tm/OTb5JJs85EdpSZnbuZ9iU+PLNoJC7NSCMIGkysHoznqea7kD9wXXcR2Ia8ykKXR68bwxnOpsq1+w0AWcBRjec/yej++5Remdk1Q81E2cgofcCIfpbsYNZ4imnEtz3AKH6a7KJ7w05Q6KITIAdYJIW4AfoAkznHzSJDWYDKVghNTuYCJ/CumHEalMJvTfaX3KcdwLJ/ZXs+lMrBS0MPP4Exu4snoeaM5qoI8HuAP0WtTuTB67DT47EUphCOUBaNYYHt1Bf3iFiPVJqVgNvkpksezXJvuInjGT0/hJqABcCPacoFfApclo1B+CNIC9uJwKygSwR6bbqJZGZl7Cl7YZ1gc5XbvOVRFXU2Xkxfj18eNZuwFoDerYs57VTLVdtRqBaDH8aIU3MZCkkVtUgoKhRV+mtl7pJQlaOsVvE0UTwFBTBF+ewpPcBM381dPYSWCoSyxHHQMQykMZUl0Mxlj3FmcxmKG8RPNacEe/sgkcqjiNzzFerozO3J9e2QTmGt5JjqN0IrTmA3AqaYur1+lEJR0zXvPhHn2CnuGspjBGT57J9vxoxReEEJ0ABYBnwKfSCn9e4cKmSAtOr8CaydtohuZuyERFNq4bDArBb8DzSU0ZL1h/2Nj3D204E/cC1Q7tcuhij20jJ7fQTtKaEgjSvmQU/ieI2zzsqsjr8LayQePl/pPd0s93fkrrPmKodFd6RTJwbNSkFIeL4TIB4YDY4D/CSEaSSlbOMdMLkF6CkE2GfeiENwwj3/YrR2ww1zuwwwD7MZpubp5zKlHFLSl71UpWE0T1tMMcxOhsFHmI0Vtx886hWOAYyOfZsBMMPgQThNBXl47X/B2uAnAlfSmT8T2roe9lUd41LCjF8QrBb9mLPO99mRt9Njox34GZ/I4N3O/YRDYjFtr3Xj9Sv4ZdZbntbVv5el1JuNdy6Wz3saTZbI4lk/oz7dRZZZNSiHTpmCmG1UfieHHjlIATEDzQTRGSnm9lPLVpJTKB5mwdLwg4kseqpWC7ufHSLwSEJh95Wxz8P7pdfvLCvL4HY+zy2HlsJ+ewgtcGV3w5XUA2EopeCmX1/KFzWccyzNcX+N6CkpAKvziZ0yhFTAaOA64UQhRBcyXUv4xKSXzyEP83necIOYjJ5rzU/TYqQXtpWfglJdTuf2Ok7jdk11ZnbZ9NJKI8y+o7lWl2pdOujfJCRshwN7VpEIRj58xhb1CiO+Bjmgb4hxNBuzR3M6wHWe6MO4E57QPgVHQ3mWzQ1WylYLTto1GFjGck5jL80yMOf8Yt9CRza7+Yb5hIADXEMyl1Vucw4nM5XF+Gyh+UF7kcoayhLsjg/PZjlIICr/4GVP4HlgNfIbm7uIKKeWhZBUsW9nssG21USncx12+005lT0FvqReaVjQX04QrecE1/SpyEzLB/EQLfsErgeMH5QAN+JXLBkMKRU3Gj/mou5Qy/Qb8EAhiPvI6JdWJRFdSp1Ip1DTbem1FmY8UfvGlFIQQzwBtpZT9hBADgDOllJOSVLaM4TmuZg09bT2KesVuq8a/ciMzOBOwF9bf0Y1L+U/Mud20oCV7AHybWdyUiFIK4fNbJvue+QZwA08FblCogWaFX/wohX8AtwHPAkgplwkhXgGyQims5Uh6sM53vM10oIhmMS6Zg2IniI2rpe2UwnU8wxemrRb30YSW7KEb37GbVr7KonoKqeeJgOMjT9vsbaHjJPhro1KojfccJn5sDg2klAtN5+LnHWYoxhlCfkh0Fo0RLwLWzWW11bkgM2aUUlAoFFb4kSa7hBBHgCYlhBA/B7YlpVRJoDW7AsW70DCz6GYetwzzKLdYnr+JJ3jQMGXWi4K52MPg6mP8jut5ml/wMrMZ57j/sh1uSmEK1zKfkUxJsXfHu/gL9/CnlOaZLk427PVzrMe9li66KPb3SSc5h3/3XX9lyhRusXil+vSxDvv44zBrln1a55wDw4YlVp7jjqs+vuOO6uMehq1cnngCLr8czrPZ3nuCi/X5jDNgisVkvcss3I7ecQcMH179u6lhB9GFpqZ7U7+7i0opPX2AbsAcYD+a2+zPgM5e44f1GaqNmyX0KeA4T+HeYkLMqaP5zDLclfwjemyV1MPcKiXI23jIMZz+sTo5ltmJ3rYEKYtoLCXIVuwMJb1M+fToEX+uadPE0pw6Vftu1Ur7Pv54KaWU8he/8JfOhRdKeeCAxf9sQj/ftq3DsyHj43/xRfW5Z5+NDV9Z6V4+KaW85JL4upNSyvJy6zj79sWXX+fcc7Uwr7+u/R45sjretGnauUcfjU3vzTelfOWV6vqywxinbl3rMGedZV/HdumZmTdvnqd4mze755EpAIuldJexnsYUIvsoDJNSniyEaAjkSCmzdpfyPMo9hTO3pu0G+9wGAfXriZiiwlq5nYjJKduQMpx0Mt1GnYzy6Wnape2Up1O96/HC+m8U4eNJMkhtKur/RY5Ls1khALT3aPUyK4VWBhPUNwzgL9zFKnrxJUc5phPGjmNh2/ZrmovoZApuswBLtkDzey/pUApB0esujDrMdGWdrfhpLs4RQtwqhOgohGihf5JWsiTxKcdwiHxPYc2taaM/n2P4jLv5C31YFWiaYbrwuqJZEU82CqFMLbNZKWRqOd3I1nI74WdK6gWR718bzkmw2E0mg6kix3OL3Sw4jeYfo8nIzXwUxkwe1VNwxurlTLQ1ahc/0wRBGOUxp5GI+cgcxliPqTAfZdr/k2147ilIKbtafKIKQQiRsRu+/sBh0WOJ4DL+7SmeWXAazURBlEIizGdUwmkYqWlKIZnUZiFTm++9thLmaONDIaYVGtcwhQ78EHNuPkd7anmbzUfGPQv8KAWdRFr7e2gZOK6R2qQMkiXQgrRykylc0yG4Ex1oVmQuYSqFjPy7ExHEZgFqVBKpNh+FRSaUIVtI1wyZRARnWEI3TJNUMkx7iuQRplLIyL85yIyfLRwOwNMxwydmJVF9nE1KoTZRG6ekZuI9W5VJKYXMpcZPVjcLYqNgn8I1lnE6sgWBjPM1ZGd6SdT7aSqpqeajVE5JzTTS4fso0XTVlNTMJUylUBhiWqHh1Dr333LPfqWgCE5tEkKJ3KsXga+mpGYufjbZyQV+BnQxxpNSTo58nxN24cLAyXwUljnHj/loD815lYscw5uZg4uDGx/8kb/wJDexnwahpZkJJOPlzPQegk4ypqSGQboEZk0U1KnET0/hXeByoCXQ2PDJaMLtKVjjRym0ZA838LRjeIHkPv4AwJ1M4hTmhFJOgKe4EYGkIv07qSadTBp09UM2KCM/dZLqdQqKxPCzeK2DlHJA0kqSJJzGFMIb+E2eG2o1OK1wI9Na+UrgZzd+egqzhRCnJq0kScJsPrITsjM4w3Oadq6y7QgyuFtTB4RTSSYJJz9CtqZMSXVKK5P+G0UsfnoKC4DpEY+p5WjNYymlzGjHP07C1aggrufvnIm78/lUu6pQPYX0kS2CK9MWr3khW+q2NuJHKUwGRgHfRnxzZz3GXkQyW+aJ9BSUUvBGKgVjsp9+v+ln6joFp/GDmiFBaiZ+zEebgeVhKwQhxC1CCCmE8LTJ8B40x6yr6OUrn39xOQB/5/roubeonjCVCnONHwGvzEeJE7aiULNaqlF1q5Gt5XbCj1L4HigQQtwhhPid/kkkcyFER+BUYJPXOLsjSmEDXbmK5+Kur6anZbyJvEAOlbxB9V55MzmDgxE32sncdCYRAa96CsFJlpdUhTNqk53sxo8k3AB8BOQT3pTUx9E27/HxiGhPVS6VloLcXrgLpEN41VPIblLpcC7TWofJdJ0dZppGkrmiOdP+n2zD85iClPLPYWYshDgL+EFK+Y1w+ReFEFcDVwPk0x+A6ZzN+UyLC+vX11GYm868j/XkrCDjAwWM4U/cyycc5x64hjBo0E8sXdrcc/hhw/aweLHWcxw58ntWr+5CRUUO5567hTff7MDIkdv58MN2vsrQuXMpGzc2BODQoYXACM466zuee+4I+vdfS0HBVrZv7w0Gj7lu7Ny5g48/Xg0cH5NHQUGBKeSYSL4HgbqWaWlxxhiOoagoDyIuWdasWQOG3rIxvB0FBQV06dIa6Bs9d8IJGyko2BBTLiOffPIxdepYP8+9erVjxoxeFBd/SUHBAfbtGwKRjaj0c82aNQMGceqp2/ngg3YUF39JRYUARtCt20oKCnbalLa6LOPGbaGgYH1ciB492gK9o/fmRL9+g1m+vGlcuJKSEpe4WjmWLv2ENWvC2So3Y/CykXNkGGEeMNf8cYkzB1hu8TkL+BJoGglXCLTyVo6hsj6lEqrkWrrH7Si+jiOkBLmGI6UEeTOTHTctL6GBlCBb8mP0pFN4u08+ZTKHCstrd3CflCDv53bXdP74x+pj7T79l8Xqc9FF1ufLyqQ8/3zt+Mknw8nL/Pngg/hz8+dLOWRI9e8ePaSsqKj+fcMN2qbopaWx8caNk7KoSCt3RYWUBw5IWVIiZVWVtsn83r3acWmplHPnOperfXvte/FiKRs21I71DeUvuUTb7Ly0tPq7qko7tqrLdu20Mh08qG1qX1oq5XPPadcuvFA7r4ctL9d+m8nLq07L7r/SxvS0j5G9e7V09TwnTtTqxhi+rEzK/fu18oCU1123Lpqmfo/792vflZXV5w8ciC/LoUPx5Tei15uUUo4YocWZO9c6jDGs8dgK/f8+cCC2jGas6siK8nIZUwc68+bNc423d697+pkEsFhKdxnrZ/bRrYbjesC5YNif0lrhnGx1XgjRH+gK6L2EDsBXQogRUsrtbgU5EHHRYGUqyqM8Eqa+WzKxZU2wp3DIpmVnTNtLT6GO4R85EKIrihwbq1rdutXXWnka6vdPE4tJyzk5sfnVrQu5hoXhubnQoUN8vLy82PSMcerUgaZNteMGDdzNCPXqad/Nm1enIyN/UX5+dTrGbzsaN9buwRi3UaPq68ay1LF56+rWhfJy+zzq2j9i0fvWycmpvj+d/HytHHo6TZpUxKRpd4/mdLxglZb5nFXdutVzkLI4UaeO/f/hFs9c5zUFP+ajJaZTnwshFgbJVEr5LdBG/y2EKASGSSl3+UnHyr3EXprR2fu4dUrHFNKJFzurdNdZoeGWVyrLAvEDoDXZLh1G3dbk+qnteB5oFkK0MHxaCSHGAWnVlWal0J9l0SmrXoW8Hi6Zs48ynUx4wdNZhtorJFOseRVZgZ+O0xK0p0igrWguBK4MoxBSyi5B4pmVwga6Bp7CmYrFa17Klg7hkupWeaoIUpfZXhf+yp+ahy3b67S24ad5/HtgkJSyK/BfoBTYn5RSecSsFIyt/UF8A8B4ZjqmocdJ5nqATFid7EVAZtKGLGFMN/Qa1mpFsN8yh9nbSFbPxWl7zDDST0YcRerxoxTuklLuE0IcA5wI/BN4JjnF8oa5dS8RcYJ3KOahEOs0gmzb6ZVsGa9IVovOS7rmMHZxklHGTGnJhjmekSn3ZCQTy6SIx49SqIx8/wz4h5TyfxBZDpwmzMLWqiVex3mCVEoFdjrNR+nYstGJTGg1GsuQaCs9E+4HUleOVHl9VaQeP0rhByHEs8AFwCwhRF2f8UPHLNArqMOnHBtz7msGO6bxHuMAOOgwpTRR/CiedLSmamqemeCCOhNJ9f+tegjZhR+hfj7wPjBWSrkXaAHclpRSBaAr31NOPn/iz3ji0rQAABhlSURBVPRgDa9EtrycwrWO8a7gX3TjO/bTkJbsog07klbGTPdjlM4xhUwRwskSYH7qIHVCNLXPY6b8xwpn/KxT2A+8Zfi9DdiWjEJ5xdgCL6QrAFXkso4elmGsOERdNtANgD20TEIp/fUUsn1qZlike5posv32ZDtKwNdcsnpyvptpKFNYG1FSqyL+WDKNmvqCe70vo5DP9jEFhSJRslopPM5vba9lkqnmXc5kGIt4gYlpK4MSWvEErZNM3l5SrVNQJEoArx+Zg9MqZF0pZMp00CUM8xSutgrvbBrsznYhl651CorsIKt7Cl4EfqYohXRTG1/iINMmM8F8lOxZU+nyK6XIDmqsUsgk85HCnUxZK1EbHOJVo94RRTw1Vin4CZNJZJKridqIF6WQ7LrMdvOUmZp2PzWdGq8Uso10uppIFulyTJcs/zzpXMuQzdT0+6sp1FiloMxHilQqI7e8lEBUZAtZrRR0NtIp7lymzT7yijIfpR4p07GaWKHITLJaKejO7srJi7u2KaIo9E13FO5I6b4dohd69IjdMrNRo/htFBs1gi5dqn8fcUTs9cMOsy+jV6y2ATViVJS9esXme/jh9vE6Rdog+QZ3kN27x4drGVkg37GjcznMZeidwBpHfYtTp/Lr5Wna1NlZZFjo/61xe1JFBuNlI+dM+sDQ6KbcvVgpJciV9IrbWDyfMnkur0uocty83e3z0ktSNm7sPfwzz0j5t7+5hzv22Orj996rPr7vPvfwdp9586RcsEDKZcu0csydK+Wf/6xdmzhRysLC2Dznz9c29NY3on/pJSk3b9bivv++lFdeaV0f5nOzZlUff/ihlDt2SLlqVfU5KaXctEnKjz+W8tJLpXz6ae3c/v1SvvWWlDNmaJvdSynlJ59I+eij2sboOkJUpzV+vNdtyjXeflvKp55aIpcvr07j88+l3LBByiOO0H6vXSvl7t1Szp4tZVWVlFOnxuZv5uBBKV9/XcqiIinffVf7FBXFh6uq0sIdPChlRUVsfVixa5f2v+zdK+XMmVJu3Cjlp5/Gx/v2Wym/+cY6jaoqKadNk/LQoepz5viHDmlh5s6dZ18YEx99JOXkyVJu3679x34oLpbynXf8xUmUpUulXL48ePx58+aFVpZMAVgsvchYL4Ey6WNUCgNYKiXIb+ifkOC3+9x9t1aZHTs6hzvvvNgX74033NN+4YXYOPrx/fdbh9+9W/tu1Mg+TSv++U8ZVQrGfIzoSuHll60epNjPzp3ad6tW1uXX2btX+92kiXW5/FCnTnX6fpWClNUvuLmMRqWQbLwoBTuCxnOLXxMFX1jUxLrxqhSy2nx0KLKdw4aIMzxFPFJmf77Jugc1zqJQxJPVbi5W05uLeIVZnJ7uosTgRYgFFUhBBWQmrnQNghLkCkVyyWqlAPBaZN+EZJIMYelXuClhqFAoUkFWm49qI8lUDsnoTSjnaxo14R4UtQOlFEIgWStnrfArlP2EzwbzUTaUUaHIZpRS8EAyWnl2afo9n2h+ftOuiS1epWgUimqUUsgykiGUa1pvQqFQBEcphRDIZEHpp2y1vcegUCiUUggFs4BMZEqqm7Ct7VNSw0QpNoUiHqUUQiAVA83JHJhOt0kqlWkpFApnlFJIE2FuGp8o2SR0VeteoUguSilkGdkkwMPCqAiy9f6VMlNkC0ophEAmm4+8xPeTdjoWrykUitShlEKWkSlC1ms5sqFlnw1lVChShVIKIRBEqCRrkZoZL2ULUn4lSBWKmklalYIQ4jdCiNVCiBVCiIfTWZYwSabATOaU1GSQKT0bJ7KhjApFqkibl1QhxAnAWcBAKeVBIUSbdJUlUTJ5TCFZU1JrkiBVvR6Fopp09hSuAx6UUh4EkFLuTGNZUk5Q81EmTWXNdlSdKBTxpFMp9ACOFUJ8KYT4WAgxPI1lSTlKICkUikwkqeYjIcQcoJ3FpTsjebcARgLDgWlCiG6RvUTN6VwNXK39Gpqs4kbJza2isjKHwsJCCgoKOXhwJFCP3r33sWpVk7jwO3fuANoCUFBQwIoVrYG+0etjx27n/fdjq6FJk0+4665WbN1an4KCjcAYAHr3/oy8vKMpL8+hQ4f9bNnSAIBPP/0UOJbKygquvHITbduWMXt2e77+ujkADz74BQUFh+LK1rlzLqNH9+bkk9dGro+JllPnrLPqsnlzd1q0WEVBQZUphTHRowceWMaKFXsYN64nZ521leuuGxpN6+yzuzN69C4KCvYCmknmtNN6Mn78VgoKiu2q2hOTJzfh3XcP4+DBXC666DsKCsp8xS8pKYnc75hoeQFuu60hU6d2YsuWVWzbllARXZESzjijByefvIOCgiJfcW+88XByciQFBVsD5f3II81ZsKAlBQXrY85X14vCTK2uGy8bOSfjA7wHnGD4/R3Q2i1eo0YDJUh57732G9hbfR56yP7ali3Vx++9J+U992jHd9+tbXjdqZP2e9Ei6/j6xvfHHKOFnzq1+lrr1saNs2V00/v4TbWtN1fXz+/bp303amR93etG4343gTfeZ6JppQu9brKlvKmiJm5OHxY1sW6AxdKDbE6n+eht4AQAIUQPIB/YlY6CJMsJnUKhUGQb6dyj+QXgBSHEcuAQcFlEm3nCr6AOQ7B7HQQ25pWOdQcKhUIRlLQpBSnlIeCX6crfDieha3ct1S4rFAqFIllk7YrmbBasibT2s/m+FQpF5pO1SkGhUCgU4ZPOMYWMJIj5SKFQJI/y8nK2bNlCWZm/qciJ0LRpU1atWpWy/MKkXr16dOjQgby8vEDxa41SSMTsokw2CkX62LJlC40bN6ZLly6IFL2MxcXFNG7cOCV5hYmUkt27d7Nlyxa6du0aKI1aYz7y2spXvQGFIrMoKyujZcuWKVMI2YwQgpYtWybUq1JKIQTMz6oxL6VkFIrEUQrBO4nWVa1RCongJtjV86pQKPxSWFhIv379AFi6dCmzZs1Kc4k0lFLwQW13Ma1QKDS7fVWV2UdYYiiloFAoFFlEYWEhPXv25NJLL6Vfv37897//ZdSoUQwZMoTzzjuPkpISAG6//Xb69OnDgAEDuPXWWwG4/PLLeeONN6JpNWrUKCbtQ4cOcffddzN16lQGDRrE1KlTU3djFmTd7KNk2Oi9jgGo8QGFIr3cfDMsXRpumoMGwRNPuIdbt24d//73v+nevTvnnHMOc+bMoWHDhjz00ENMnjyZX//610yfPp3Vq1cjhGDv3r2e8s/Pz+fee+9l8eLF/O1vf0vwbhIn65SCjl+zTBiriO3SUMpCoaj5dO7cmZEjRzJz5kxWrlzJ6NGjAa2lP2rUKJo2bUq9evW48sorGT9+POPHj09ziYORtUohTIwKRrmgUCgyFy8t+mTRsGFDQBtTOOWUU3j11VfjwixcuJCPPvqIN954g7/97W/MnTuXOnXqRMcgqqqqOHQoft+TTCJrxxTCbJ0nmpa5J6F6DgpFzWXkyJF8/vnnrF+vbVpUWlrK2rVrKSkpoaioiNNPP53HH3+cb775BoAuXbqwZMkSAGbMmEF5eXlcmo0bN6a4OLHNqMIia5VCsggi0FUPQaGoPbRu3ZoXX3yRiy66iAEDBjBq1ChWr15NcXEx48ePZ8CAARxzzDFMnjwZgKuuuoqPP/6YgQMHMn/+/GiPw8gJJ5zAypUr1UBzIihBrFAoUkWXLl1Yvnx59PeJJ57IokWL4sItXLgw7lzbtm1ZsGBB9PdDDz0Ul2aLFi0s00sHqqegUCgUiihZpxSaNKkA4LTTvIXv0UP7jkwUsKR58+rjfv3glFO0Y/372mu1b6/+pYYOrT6+/vrq4/794895pV497fs3v/EfNxFat9a+u3e3vn7BBakrS6Icc0y6S6BQZD5ZZz5q3LicrVu14xkz4MwzY69LqSmM997Tfk+bBgMHwr599mk2aBA7ltC1a+zvO+7QPgCDB8PXX8OSJbHC30iPHtZjE8uWOd+bE3l56RnA3rnT/lq2Dah/+mm6S6BQZD5Z11PwgtV4QyoEmBrnUCgU2U5WK4Ww9kxWKBQKhUZWK4VMQSkhhUJRU8hqpeDF7UQq7d7ZZmNXKBQKMzVSKaQ6T9VTUCgUfqisrEx3EWzJaqXgh7AVSFj+khQKReYzYcIEhg4dSt++fXnuueeYMmUKt912W/T6iy++yA033ADASy+9xIgRIxg0aBDXXHNNVAE0atSIW265Jbqy+d5772X48OH069ePq6++GhkRJIsWLWLAgAEMGjSI2267LboRT2VlJbfddhvDhw9nwIABPPvss0m516ybkmrEizBORSteKQWFIkWkyXf2Cy+8QIsWLThw4ADDhw/no48+YvTo0TzyyCMATJ06lTvvvJNVq1YxdepUPv/8c/Ly8rj++ut5+eWXufTSSyktLeWoo47iscceA6BPnz7cfffdAFxyySXMnDmTM844gyuuuIJ//OMfjBo1ittvvz1ahueff56mTZuyaNEiDh48yOjRozn11FPp6nUBlUdqpFJI15iCMiMpFDWTJ598kunTpwOwefNmNmzYQLdu3ViwYAFHHnkkq1evZvTo0Tz99NMsWbKE4cOHA3DgwAHatGkDQG5uLueee240zXnz5vHwww+zf/9+9uzZQ9++fTn22GMpLi5m1KhRAFx88cXMnDkTgA8++IBly5ZFN+wpKipi3bp1SikERQlshaIGkAbf2QUFBcyZM4f58+fToEEDxowZQ1lZGRdeeCHTpk2jV69enH322QghkFJy2WWX8cADD8SlU69ePXJzcwEoKyvj+uuvZ/HixXTs2JF77rmHsrIyx3JIKXnqqacYO3ZsUu5TJ6vHFJTZRqFQJJuioiKaN29OgwYNWL16ddS53dlnn80777zDq6++yoUXXgjASSedxBtvvMHOiCuAPXv2sHHjxrg0dQXQqlUrSkpKoq3/Zs2a0bhxY7788ksAXnvttWicsWPH8swzz0Rdb69du5bS0tLQ77fW9BTCUiBq9pFCUbsYN24cU6ZMoXfv3vTs2ZORI0cC0Lx5c3r37s3KlSsZMWIEoI0TTJo0iVNPPZWqqiry8vJ4+umn6dy5c0yazZo146qrrqJfv360a9cuam4CbezgqquuIicnh+OPP56mTZsC8Ktf/YrCwkKGDBmClJLWrVvz9ttvh36/Wa0UvAj6ZPUm0uVKQ6FQpJa6desye/Zsy2u6vd/IBRdcwAUWniJLSkpifk+aNIlJkybFhevbty/LIo7SHnzwQYYNGwZATk4O999/P/fff7/ve/BDjVcKCoVCkU3873//44EHHqCiooLOnTvz4osvpjT/Gq8UUjklVZmRFApFotj1NFJFVg80+0H1KhQKhcKdGqkU0rVOQaFQJAepXmTPJFpXaVMKQohBQogFQoilQojFQogRftPIFN9HCoUiedSrV4/du3crxeABKSW7d++mnr5VYwDSOabwMPBnKeVsIcTpkd9j/CSQzmdEjR8oFKmhQ4cObNmyhR9//DFleZaVlSUkWNNJvXr16NChQ+D46VQKEmgSOW4KbPWdgGo4KBQ1nry8vNBdObhRUFDA4MGDU5pnppDOMYWbgUeEEJuBR4E7/CbQtq31+T59qo8bN9a+8/KqzzVr5jenavr2jU3XmF/PnsHTBW2vaDPt2iWWpkKhUPhBJNNOJ4SYA1iJtTuBk4CPpZRvCiHOB66WUp5sk87VwNUArVu3Hjpt2rTotYULW9CtWwkrVjTh8MPL6N69hMpKwZQp3RgwoIhjj90VDbtsWVN++imPkSP38PXXzejZs5itW+vTt+8+z/dUVpbDypVNGDJkLz/9lMf06YczcWIhS5Y0p3//IvLzqzynZWTNmka0anWIli0PxZzfsyePHTvq0bt3sWW87dvrsn9/Hdq02UGjRo1c89m2rR5lZbl07Rr+8vhMpaSkxFPd1DZUvdhTE+vmhBNOWCKlHOYWLqlKwTFjIYqAZlJKKYQQQJGUsolbvJ49e8o1a9Ykv4BZRkFBAWPGjEl3MTISVTfWqHqxpybWjRDCk1JI55jCVuB4oAA4EVjnJdLatWtLhBBKK8TTCtjlGqp2ourGGlUv9tTEuunsHiS9SuEq4K9CiDpAGRHzkAfWeNF2tQ0hxGJVL9aourFG1Ys9tblu0qYUpJSfAUPTlb9CoVAo4qmRK5oVCoVCEYxsVArPpbsAGYqqF3tU3Vij6sWeWls3aZt9pFAoFIrMIxt7CgqFQqFIElmjFIQQ44QQa4QQ64UQt6e7PKlACPGCEGKnEGK54VwLIcSHQoh1ke/mkfNCCPFkpH6WCSGGGOJcFgm/TghxWTruJUyEEB2FEPOEECuFECuEEDdFzqu6EaKeEGKhEOKbSN38OXK+qxDiy0gdTBVC5EfO1438Xh+53sWQ1h2R82uEEMndLT5FCCFyhRBfCyFmRn6rejEjpcz4D5ALfAd0A/KBb4A+6S5XCu77OGAIsNxw7mHg9sjx7cBDkePTgdmAAEYCX0bOtwC+j3w3jxw3T/e9JVgv7YEhkePGwFqgj6obSeQeG0WO84AvI/c8Dbgwcn4KcF3k+HpgSuT4QmBq5LhP5D2rC3SNvH+56b6/EOrnd8ArwMzIb1Uvpk+29BRGAOullN9LKf+/vXsPsaIM4zj+/UWWoaElGuVWKgmFpYYhiRWRuZVFViwYKYX2V1R0AQuxC4hQYVQWEUJSlpbRBRSK1FbpamSpqCTFRkGXrY1MaZMu6tMf73vG8ay3aN3T7vl9YHDOM3PGmQf2vGfeec/z/gUsBSbX+JyOuIh4D9hWFZ4MLMrri4BrSvEXIvkY6C/pZOAyYFVEbIuIX4FVwOVH/uyPnIhojYj1ef03YCswGOeGfI2VyYB75SVIPxB9Lcerc1PJ2WvAhFxhYDKwNCL+jIivgRbS32G3JakBuBJ4Nr8WzksH3aVRGAx8W3r9XY7Vo5MiojWv/whUygIeKEc9Onf5tv5c0jdi54aii2Qj0EZq6L4CtkfErrxL+TqLHOTtO4AB9MzcPAHcA1QKlA3AeemguzQKth+R7mfrdviYpL7A68CdEbFPVcN6zk1E7I6I0UAD6VvsmTU+pZqTdBXQFhGf1fpc/u+6S6PwPXBq6XVDjtWjn3LXB/nfthw/UI56ZO4k9SI1CEsi4o0cdm5KImI7sAYYR+oyq1QwKF9nkYO8vR/wCz0vN+OBqyV9Q+p+vgSYj/PSQXdpFNYBw/NIgWNID36W1/icamU5UBklcxOwrBS/MY+0OZ9UdbYVWAE0Sjohj8ZpzLFuK/ftLgS2RsRjpU3OjTRQUv+8fhwwkfTMZQ3QlHerzk0lZ03A6nyXtRy4Po/CGQoMBz7pmqvofBExKyIaImII6fNjdURMpc7zsl+1ftJ9uAtpBMmXpP7R2bU+ny665peBVuBvUt/lzaR+zWZSVdl3gBPzvgKezvnZDJxXOs4M0gOxFmB6ra+rE/JyAalraBOwMS+TnJsAGAlsyLnZAjyQ48NIH14twKvAsTneO79uyduHlY41O+fsC+CKWl9bJ+boYvaOPnJeqhb/otnMzArdpfvIzMy6gBsFMzMruFEwM7OCGwUzMyu4UTAzs4IbBbPDIGmOpEs74Tjth97LrHY8JNWsC0lqj4i+tT4PswPxnYLVLUnT8twDGyUtyIXk2iU9nuciaJY0MO/7vKSmvP5wnsthk6RHc2yIpNU51izptBwfKmmtpM2S5lb9/zMlrcvvqcx70EfSm3k+hC2SpnRtVqzeuVGwuiTpLGAKMD5S8bjdwFSgD/BpRIwA3gUerHrfAOBaYEREjAQqH/RPAYtybAnwZI7PB56JiHNIv06vHKeRVCJhLDAaGCPpIlLp7h8iYlREnA283ekXb3YQbhSsXk0AxgDrcpnpCaSSB3uAV/I+i0klNcp2AH8ACyVdB+zM8XGkyVsAXiy9bzypXEklXtGYlw3AelIl0+GkMhwTJT0i6cKI2PEfr9PsXzn60LuY9UgifbOftU9Qur9qv30eukXELkljSY1IE3AbqeLmwezvwZ2AhyJiQYcNabrQScBcSc0RMecQxzfrNL5TsHrVDDRJGgTF/M6nk/4mKlUzbwA+KL8pz+HQLyLeAu4CRuVNH5Gqb0Lqhno/r39YFa9YAczIx0PSYEmDJJ0C7IyIxcA80nSsZl3GdwpWlyLic0n3ASslHUWqRHsr8DswNm9rIz13KDseWCapN+nb/t05fjvwnKSZwM/A9By/A3hJ0r3sLctMRKzMzzXWpkrgtAPTgDOAeZL25HO6pXOv3OzgPCTVrMRDRq3eufvIzMwKvlMwM7OC7xTMzKzgRsHMzApuFMzMrOBGwczMCm4UzMys4EbBzMwK/wBa/frtfIHcqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dqn._logger.graph(\"sum_reward\",average_range=[3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  19.,   30.,   63.,  131.,  217.,  662.,  558.,  599.,  614.,\n",
       "        1857.]),\n",
       " array([-8., -7., -6., -5., -4., -3., -2., -1.,  0.,  1.,  2.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEU9JREFUeJzt3X+sX3V9x/Hna0XIojJwvTJsy4qmmADTqpWxOByODQougvuDtX8I/oiFCYtsJgY0GcyFDH8gkegwVRogUZCNIc2sYiVGsmRFLtiV33JBGK0VqizghsMV3vvjnsrXcm/v7f1+7/3S+3k+km/u+b6/n3PO+6RpX/d8zjnfpqqQJLXpN4bdgCRpeAwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsP2G3YDU1m4cGEtXbp02G1I0j7jjjvu+GlVjUxn7Es+BJYuXcro6Oiw25CkfUaSR6c71ukgSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlq2Ev+iWFJGqal539jKPt95JJ3zsl+PBOQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhU4ZAknVJnkhyd0/ta0k2d69Hkmzu6kuT/KLnsy/2rPOWJHclGUtyeZLMziFJkqZrOg+LXQV8HrhmV6Gq/mLXcpJLgad6xj9UVcsn2M4VwAeB24ANwErgm3vfsiRpUKY8E6iqW4EnJ/qs+23+dODaPW0jyaHAgVW1qaqK8UA5be/blSQNUr/XBI4DHq+qB3tqhyf5QZLvJTmuqy0CtvaM2drVJElD1O93B63m188CtgOHVdXPkrwF+HqSo/Z2o0nWAGsADjvssD5blCRNZsZnAkn2A/4c+NquWlU9W1U/65bvAB4CjgC2AYt7Vl/c1SZUVWurakVVrRgZGZlpi5KkKfQzHfQnwP1V9atpniQjSRZ0y68FlgEPV9V24Okkx3bXEc4Abupj35KkAZjOLaLXAv8OvD7J1iQf6D5axYsvCL8d2NLdMvrPwNlVteui8oeALwNjjJ8heGeQJA3ZlNcEqmr1JPX3TlC7AbhhkvGjwNF72Z8kaRb5xLAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUsOn8R/PrkjyR5O6e2kVJtiXZ3L1O6fnsgiRjSR5IclJPfWVXG0ty/uAPRZK0t6ZzJnAVsHKC+mVVtbx7bQBIciSwCjiqW+cfkyxIsgD4AnAycCSwuhsrSRqi/aYaUFW3Jlk6ze2dClxXVc8CP0oyBhzTfTZWVQ8DJLmuG3vvXncsSRqYfq4JnJtkSzdddHBXWwQ81jNma1ebrC5JGqKZhsAVwOuA5cB24NKBdQQkWZNkNMnojh07BrlpSVKPGYVAVT1eVc9V1fPAl3hhymcbsKRn6OKuNll9su2vraoVVbViZGRkJi1KkqZhRiGQ5NCet+8Gdt05tB5YleSAJIcDy4DvA7cDy5IcnmR/xi8er59525KkQZjywnCSa4HjgYVJtgIXAscnWQ4U8AhwFkBV3ZPkesYv+O4Ezqmq57rtnAvcDCwA1lXVPQM/GknSXpnO3UGrJyhfuYfxFwMXT1DfAGzYq+4kSbPKJ4YlqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhk0ZAknWJXkiyd09tU8nuT/JliQ3Jjmoqy9N8oskm7vXF3vWeUuSu5KMJbk8SWbnkCRJ0zWdM4GrgJW71TYCR1fVG4AfAhf0fPZQVS3vXmf31K8APggs6167b1OSNMemDIGquhV4crfat6tqZ/d2E7B4T9tIcihwYFVtqqoCrgFOm1nLkqRBGcQ1gfcD3+x5f3iSHyT5XpLjutoiYGvPmK1dbUJJ1iQZTTK6Y8eOAbQoSZpIXyGQ5OPATuArXWk7cFhVvQn4G+CrSQ7c2+1W1dqqWlFVK0ZGRvppUZK0B/vNdMUk7wX+DDihm+Khqp4Fnu2W70jyEHAEsI1fnzJa3NUkSUM0ozOBJCuBjwLvqqpneuojSRZ0y69l/ALww1W1HXg6ybHdXUFnADf13b0kqS9TngkkuRY4HliYZCtwIeN3Ax0AbOzu9NzU3Qn0duATSf4PeB44u6p2XVT+EON3Gv0m49cQeq8jSJKGYMoQqKrVE5SvnGTsDcANk3w2Chy9V91JkmaVTwxLUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDZtWCCRZl+SJJHf31F6VZGOSB7ufB3f1JLk8yViSLUne3LPOmd34B5OcOfjDkSTtjemeCVwFrNytdj5wS1UtA27p3gOcDCzrXmuAK2A8NIALgd8HjgEu3BUckqThmFYIVNWtwJO7lU8Fru6WrwZO66lfU+M2AQclORQ4CdhYVU9W1X8BG3lxsEiS5lA/1wQOqart3fJPgEO65UXAYz3jtna1yeovkmRNktEkozt27OijRUnSngzkwnBVFVCD2Fa3vbVVtaKqVoyMjAxqs5Kk3fQTAo930zx0P5/o6tuAJT3jFne1yeqSpCHpJwTWA7vu8DkTuKmnfkZ3l9CxwFPdtNHNwIlJDu4uCJ/Y1SRJQ7LfdAYluRY4HliYZCvjd/lcAlyf5APAo8Dp3fANwCnAGPAM8D6Aqnoyyd8Dt3fjPlFVu19sliTNoWmFQFWtnuSjEyYYW8A5k2xnHbBu2t1JkmaVTwxLUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDZtxCCR5fZLNPa+nk5yX5KIk23rqp/Ssc0GSsSQPJDlpMIcgSZqpaf1H8xOpqgeA5QBJFgDbgBuB9wGXVdVnescnORJYBRwFvAb4TpIjquq5mfYgSerPoKaDTgAeqqpH9zDmVOC6qnq2qn4EjAHHDGj/kqQZGFQIrAKu7Xl/bpItSdYlObirLQIe6xmztau9SJI1SUaTjO7YsWNALUqSdtd3CCTZH3gX8E9d6QrgdYxPFW0HLt3bbVbV2qpaUVUrRkZG+m1RkjSJQZwJnAzcWVWPA1TV41X1XFU9D3yJF6Z8tgFLetZb3NUkSUMyiBBYTc9UUJJDez57N3B3t7weWJXkgCSHA8uA7w9g/5KkGZrx3UEASV4O/ClwVk/5U0mWAwU8suuzqronyfXAvcBO4BzvDJKk4eorBKrqf4Df3q32nj2Mvxi4uJ99SpIGxyeGJalhhoAkNcwQkKSGGQKS1LC+LgxLLVt6/jeGst9HLnnnUPar+ckzAUlqmCEgSQ0zBCSpYYaAJDXMC8OSXvKGdRG+BZ4JSFLDPBOQNG3+Rj7/eCYgSQ0zBCSpYYaAJDXMEJCkhnlhWNrHeHFWg+SZgCQ1rO8QSPJIkruSbE4y2tVelWRjkge7nwd39SS5PMlYki1J3tzv/iVJMzeoM4F3VNXyqlrRvT8fuKWqlgG3dO8BTgaWda81wBUD2r8kaQZmazroVODqbvlq4LSe+jU1bhNwUJJDZ6kHSdIUBhECBXw7yR1J1nS1Q6pqe7f8E+CQbnkR8FjPulu7miRpCAZxd9AfVtW2JK8GNia5v/fDqqoktTcb7MJkDcBhhx02gBYlSRPp+0ygqrZ1P58AbgSOAR7fNc3T/XyiG74NWNKz+uKutvs211bViqpaMTIy0m+LkqRJ9BUCSV6e5JW7loETgbuB9cCZ3bAzgZu65fXAGd1dQscCT/VMG0mS5li/00GHADcm2bWtr1bVt5LcDlyf5APAo8Dp3fgNwCnAGPAM8L4+9y9J6kNfIVBVDwNvnKD+M+CECeoFnNPPPiVJg+MTw5LUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlhhoAkNcwQkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYYaAJDXMEJCkhhkCktQwQ0CSGmYISFLDZhwCSZYk+W6Se5Pck+TDXf2iJNuSbO5ep/Ssc0GSsSQPJDlpEAcgSZq5fv6j+Z3AR6rqziSvBO5IsrH77LKq+kzv4CRHAquAo4DXAN9JckRVPddHD5KkPsz4TKCqtlfVnd3yz4H7gEV7WOVU4LqqeraqfgSMAcfMdP+SpP4N5JpAkqXAm4DbutK5SbYkWZfk4K62CHisZ7Wt7Dk0JEmzrO8QSPIK4AbgvKp6GrgCeB2wHNgOXDqDba5JMppkdMeOHf22KEmaRF8hkORljAfAV6rqXwCq6vGqeq6qnge+xAtTPtuAJT2rL+5qL1JVa6tqRVWtGBkZ6adFSdIe9HN3UIArgfuq6rM99UN7hr0buLtbXg+sSnJAksOBZcD3Z7p/SVL/+rk76G3Ae4C7kmzuah8DVidZDhTwCHAWQFXdk+R64F7G7yw6xzuDJGm4ZhwCVfVvQCb4aMMe1rkYuHim+5QmsvT8bwy7BWmf5RPDktQwQ0CSGmYISFLDDAFJapghIEkNMwQkqWGGgCQ1zBCQpIb188Sw9Cs+sCXtmzwTkKSGGQKS1DBDQJIaZghIUsMMAUlqmCEgSQ0zBCSpYT4nMM94v76kveGZgCQ1zBCQpIbN+XRQkpXA54AFwJer6pK57mG2OSUjaV8xp2cCSRYAXwBOBo4EVic5ci57kCS9YK7PBI4BxqrqYYAk1wGnAvfOxs78jVyS9myurwksAh7reb+1q0mShuAleYtokjXAmu7tfyd5YIabWgj8dDBd7TM85vmvteOFBo85n+zrmH93ugPnOgS2AUt63i/uar+mqtYCa/vdWZLRqlrR73b2JR7z/Nfa8YLHPJvmejrodmBZksOT7A+sAtbPcQ+SpM6cnglU1c4k5wI3M36L6Lqqumcue5AkvWDOrwlU1QZgwxztru8ppX2Qxzz/tXa84DHPmlTVXOxHkvQS5NdGSFLD5n0IJFmeZFOSzUlGkxwz7J5mW5K/SnJ/knuSfGrY/cyVJB9JUkkWDruX2Zbk092f8ZYkNyY5aNg9zZYkK5M8kGQsyfnD7me2JVmS5LtJ7u3+Dn94Nvc370MA+BTwd1W1HPjb7v28leQdjD+F/caqOgr4zJBbmhNJlgAnAv857F7myEbg6Kp6A/BD4IIh9zMrGv2qmZ3AR6rqSOBY4JzZPOYWQqCAA7vl3wJ+PMRe5sJfApdU1bMAVfXEkPuZK5cBH2X8z3veq6pvV9XO7u0mxp+5mY9+9VUzVfVLYNdXzcxbVbW9qu7sln8O3McsfrNCCyFwHvDpJI8x/lvxvPyNqccRwHFJbkvyvSRvHXZDsy3JqcC2qvqPYfcyJO8HvjnsJmZJ0181k2Qp8Cbgttnax0vyayP2VpLvAL8zwUcfB04A/rqqbkhyOnAl8Cdz2d+gTXG8+wGvYvw08q3A9UleW/v4bWBTHPPHGJ8Kmlf2dMxVdVM35uOMTx98ZS570+xL8grgBuC8qnp61vazj//bMKUkTwEHVVUlCfBUVR041Xr7qiTfAj5ZVd/t3j8EHFtVO4bb2exI8nvALcAzXWkx41N+x1TVT4bW2BxI8l7gLOCEqnpmiuH7pCR/AFxUVSd17y8AqKp/GGpjsyzJy4B/BW6uqs/O5r5amA76MfBH3fIfAw8OsZe58HXgHQBJjgD2Zx5/8VZV3VVVr66qpVW1lPHpgjc3EAArGb8G8q75GgCd5r5qpvtl9UrgvtkOAJgn00FT+CDwuST7Af/LC99OOl+tA9YluRv4JXDmvj4VpAl9HjgA2Dj+bwabqurs4bY0eI1+1czbgPcAdyXZ3NU+1n3bwsDN++kgSdLkWpgOkiRNwhCQpIYZApLUMENAkhpmCEhSwwwBSWqYISBJDTMEJKlh/w/7iLuVBdn14wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(dqn._logger.result()[\"sum_reward\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the reward graph, we can observe the agent is making multiple mistakes in the beginning, but as it experience more steps, the agent gradually generates better reward value per episode.    \n",
    "The histogram of the reward represents the frequency of the total reward. From the reward graph, it might be seen as an oscilating graph, but from the histogram, we can observe that the agent is scoring +2 reward frequently, thus we can tell the agent is scoring good during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16008818 0.19039474 0.16921243 0.15912674 0.1647401  0.15643784]]\n",
      "[[0.16243903 0.19450851 0.15988185 0.1620662  0.16282544 0.15827896]]\n"
     ]
    }
   ],
   "source": [
    "print(softmax(model(np.array([1,1,1]+[0 for _ in range(6)]+[0 for _ in range(6)])[None,...])))\n",
    "print(softmax(model(np.array([-1,-1,-1]+[0 for _ in range(6)]+[0 for _ in range(6)])[None,...])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
