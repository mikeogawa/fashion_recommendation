{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this Project, we will demonstrate how to use deep reinforcement learning to recommend good pairs of t-shirts and jeans to customers.  \n",
    "\n",
    "### Problem\n",
    "\n",
    "**Recommend users colored t-shirt and jeans that match their taste**\n",
    "\n",
    "\n",
    "### Key Assumption\n",
    "\n",
    "Here we will base our assumption based on the following:   \n",
    "- Users will be recommended colors of t-shirts and jeans, sequentially.\n",
    "- If the color does not match the user's taste, the the user will ask for another recommendation.\n",
    "- The recommendation system will recommend another color until the color matches the user's taste.\n",
    "\n",
    "### Detailed Assumption\n",
    "\n",
    "Here we will define the problem base on the following assumption:\n",
    "- The recommendation system will propose multiple colors of t-shirts, and then jeans.\n",
    "- After both are finished, episode terminates.\n",
    "- User's will not quite when asking for recommendation.\n",
    "- User's can be grouped into A and B, and each group has a taste distrubtion.\n",
    "- User's are defined based on 3 features.\n",
    "- User's will likely choose the color of their jeans that matches their t-shirt.\n",
    "- 6 colors will exist for t-shirts and jeans, respectively.\n",
    "- If the color matches the user's taste, we give a reward of +1, else -1.   \n",
    "    ex)    \n",
    "    If t-shirt and jeans were successfully recommended without making any mistakes, +2 reward is given.   \n",
    "    If both used all actions to guess user's taste, then total reward of -10 in episode is given.\n",
    "\n",
    "- If the color matches the user's taste, then it will change its target clothes.   \n",
    "    ex)   \n",
    "    If t-shirt recommendation succeeds, the recommendation system will recommend jeans.   \n",
    "    If jeans succeed, it will terminate the episode\n",
    "\n",
    "**Note**\n",
    "This notebook is based on groups choosing colors **stochastically/deterministically**.   \n",
    "Users will have different taste within a group but will deterministically choose the same color shirt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.lamda.nju.edu.cn/yuy/GetFile.aspx?File=papers/kdd18-RobustDQN.pdf&AspxAutoDetectCookieSupport=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will generate user's unique data with 3 features.   \n",
    "We will generate x1 as Group A's data and x2 as Group B's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=np.random.normal(-1,0.1,(sample_data//2,3))\n",
    "x2=np.random.normal(1,0.1,(sample_data//2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-shirt and Jeans Consuming Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will generate purchase probability for groups A and B.   \n",
    "Here, we will assume users can choose 6 different colored t-shirt and jeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=np.array([0.9,0.02,0.02,0.02,0.02,0.02])\n",
    "p2=np.array([0.02,0.9,0.02,0.02,0.02,0.02])\n",
    "\n",
    "\n",
    "def shirt(idx):\n",
    "    pr=p1 if idx==0 else p2\n",
    "    pr = pr/pr.sum()\n",
    "    return np.random.choice(len(p1),p=pr)\n",
    "\n",
    "# if customer buys certain colored shirt, the customer will have a high probability of buying the same colored jeans\n",
    "def jeans(idx):\n",
    "    p_=np.zeros((len(p1),))\n",
    "    p_[idx]=1\n",
    "    pr=np.where(p_==1,0.8,0.0)\n",
    "    pr = pr/pr.sum()\n",
    "    return np.random.choice(len(p1),p=pr)\n",
    "\n",
    "# generates data\n",
    "def out_data_prob(idx,size):\n",
    "    res = np.zeros((size,2))\n",
    "    for i in range(size):\n",
    "        r=shirt(idx)\n",
    "        j=jeans(r)\n",
    "        res[i,0]=r\n",
    "        res[i,1]=j\n",
    "    return res\n",
    "    \n",
    "\n",
    "z1=out_data_prob(0,sample_data//2)\n",
    "z2=out_data_prob(1,sample_data//2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1=np.concatenate((x1,z1),axis=1)\n",
    "r2=np.concatenate((x2,z2),axis=1)\n",
    "\n",
    "dataset=np.concatenate([r1,r2],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modifying Filter of RenomRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "\n",
    "    return y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renom_rl.utility.filter import DiscreteNodeChooser\n",
    "from renom_rl.utility.fixer import transform_node_2_numpy\n",
    "\n",
    "class MaskMaxNodeChooser(DiscreteNodeChooser):\n",
    "\n",
    "    \n",
    "    def __call__(self,x,y):\n",
    "        return self.forward(x,y)\n",
    "    \n",
    "    def forward(self, node_var, mask):\n",
    "\n",
    "        node_var = transform_node_2_numpy(node_var)\n",
    "        \n",
    "        res = softmax(node_var - np.where(mask[None,...],0,100000))\n",
    "\n",
    "        max_list = np.argmax(res, axis=1).reshape((-1, 1))\n",
    "        \n",
    "        if len(max_list) == 1:\n",
    "            return int(max_list)\n",
    "        else:\n",
    "            return max_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Import and Modify ReNomRL's DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will use ReNom RL and modify it.   \n",
    "For this recommendation system, we will use DQN.   \n",
    "To simplify what DQN is, DQN is an algorithm that chooses action based on expected future reward.   \n",
    "It explores action using epsilon greedy algorithm.   \n",
    "Exploitation and exploration rate shifts based on how much steps the agent takes.   \n",
    "For this example, we gradually shift the action decision from exploration to exploitation by steps.   \n",
    "For further understanding, go to renom.jp.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "from numbers import Number\n",
    "import inspect\n",
    "import renom as rm\n",
    "\n",
    "from renom_rl.utility.replaybuffer import ReplayBuffer\n",
    "from renom_rl import AgentBase\n",
    "from renom_rl.environ.env import BaseEnv\n",
    "from renom_rl.utility.gradients import GradientClipping\n",
    "from renom_rl.utility.filter import EpsilonGreedyFilter, EpsilonSLFilter, EpsilonCFilter, DiscreteNodeChooser, ProbNodeChooser, MaxNodeChooser\n",
    "from renom_rl.utility.logger import Logger, DQNLogger, AVAILABLE_KEYS\n",
    "from renom_rl.utility.fixer import fix_envs_testenvs, fix_single_env, fix_optimizer,\\\n",
    "    fix_action_range, check_shape, check_reset_method, check_output_state, \\\n",
    "    check_step_method, fix_logger, fix_tuple_shape, fix_instance, fix_loss_function, fix_instance2, \\\n",
    "    ArgumentCheck, decorator, test_decorator\n",
    "from renom_rl.utility.additional_modules import deepcopy\n",
    "\n",
    "_dqn_keys = AVAILABLE_KEYS[\"dqn\"][\"logger\"]\n",
    "_dqn_keys_epoch = AVAILABLE_KEYS[\"dqn\"][\"logger_epoch\"]\n",
    "\n",
    "\n",
    "class DQN(AgentBase):\n",
    "\n",
    "    def __init__(self, env, q_network, logger=None,\n",
    "                 batch_size=32, update_period=10000, train_frequency=4,\n",
    "                 optimizer=None, gamma=0.99, buffer=None,\n",
    "                 node_selector=None, test_node_selector=None,\n",
    "                 action_filter=None, test_action_filter=None,\n",
    "                 gradient_clipping=None, loss_func=None, initialize=True):\n",
    "\n",
    "        super(DQN, self).__init__()\n",
    "        local_init = locals()\n",
    "        self._arg_check = ArgumentCheck(list(local_init.keys()), remove=[\n",
    "                                        \"__class__\", \"self\", \"env\", \"q_network\", \"logger\"])\n",
    "\n",
    "        kwargs_set = lambda **kwargs: kwargs\n",
    "        self._arg_base = kwargs_set(batch_size=[None, int, fix_instance2, {\"positive\": True, \"non_neg\": True}],\n",
    "                                    update_period=[None, int, fix_instance2,\n",
    "                                                   {\"positive\": True, \"non_neg\": True}],\n",
    "                                    train_frequency=[None, int, fix_instance2,\n",
    "                                                     {\"positive\": True, \"non_neg\": True}],\n",
    "                                    optimizer=[rm.Rmsprop(lr=0.00025, g=0.95),\n",
    "                                               rm.Optimizer, fix_instance],\n",
    "                                    gamma=[None, float, fix_instance2, {\n",
    "                                        \"positive\": True, \"range\": [0., 1.]}],\n",
    "                                    buffer=[ReplayBuffer(), ReplayBuffer, fix_instance],\n",
    "                                    node_selector=[\n",
    "                                        MaskMaxNodeChooser(), DiscreteNodeChooser, fix_instance],\n",
    "                                    test_node_selector=[\n",
    "                                        MaskMaxNodeChooser(), DiscreteNodeChooser, fix_instance],\n",
    "                                    action_filter=[EpsilonSLFilter(epsilon_step=int(\n",
    "                                        0.8 * 50000)), EpsilonGreedyFilter, fix_instance],\n",
    "                                    test_action_filter=[\n",
    "                                        EpsilonCFilter(), EpsilonGreedyFilter, fix_instance],\n",
    "                                    gradient_clipping=[None, GradientClipping, fix_instance],\n",
    "                                    loss_func=[rm.ClippedMeanSquaredError(), None, fix_instance],\n",
    "                                    initialize=[None, bool, fix_instance2],\n",
    "                                    )\n",
    "        # Set Models.\n",
    "        self._q_network = fix_instance(q_network, None, rm.Model, \"q_network\")\n",
    "        self._target_q_network = deepcopy(self._q_network)\n",
    "        self._best_q_network = deepcopy(self._q_network)\n",
    "        # logger\n",
    "        self._logger = fix_logger(logger, _dqn_keys, _dqn_keys_epoch, DQNLogger())\n",
    "        # Check Env class type.\n",
    "        envs, test_env = fix_envs_testenvs(env)\n",
    "        self._env, self._test_env, state_shape, action_shape = fix_single_env(envs, test_env)\n",
    "\n",
    "\n",
    "        # Set common params\n",
    "        res = self._fixer(local_init)\n",
    "        for k, v in res.items():\n",
    "            self._arg_base[k][0] = v\n",
    "            self._arg_base[k][2] = fix_instance\n",
    "            self.__dict__[\"_%s\" % k] = v\n",
    "        self._loss_func = fix_loss_function(loss_func, rm.ClippedMeanSquaredError())\n",
    "        _ = self._buffer([1, ], state_shape)\n",
    "\n",
    "        # Reset Model\n",
    "        if initialize:\n",
    "            self._initializer()\n",
    "\n",
    "        # action_filter_during_fit\n",
    "        self._action_filter_during_fit = self._action_filter\n",
    "\n",
    "        # private info\n",
    "        self._private_info = {**local_init, **{k: v[0] for k, v in self._arg_base.items()}}\n",
    "        self._private_info_test = self._push_test_info()\n",
    "\n",
    "    def _initializer(self):\n",
    "        '''Target q-network is initialized with same neural network weights of q-network.'''\n",
    "        # Reset weight.\n",
    "#         for layer in self._q_network.iter_models():\n",
    "#             if hasattr(layer, \"params\"):\n",
    "#                 layer.params = {}\n",
    "\n",
    "#         for layer in list(self._target_q_network.iter_models()):\n",
    "#             if hasattr(layer, \"params\"):\n",
    "#                 layer.params = {}\n",
    "\n",
    "\n",
    "    def _action(self, state, node_selector, env):\n",
    "        \"\"\"This method returns an action according to the given state.\n",
    "        \"\"\"\n",
    "        self._q_network.set_models(inference=True)\n",
    "        act = self._q_network(np.array([state for _ in range(*env.action_shape)]), np.array(np.arange(*env.action_shape)).reshape(-1,1))\n",
    "        act = act.reshape(1,-1)\n",
    "        return node_selector(act,env.mask())\n",
    "\n",
    "    def _rec_copy(self, obj1, obj2):\n",
    "        \"\"\"This function copies the batch normalization parameters\"\"\"\n",
    "        for item_keys in obj1.__dict__.keys():\n",
    "            if isinstance(obj1.__dict__[item_keys], rm.BatchNormalize):\n",
    "                obj1.__dict__[item_keys]._mov_mean = obj2.__dict__[item_keys]._mov_mean\n",
    "                obj1.__dict__[item_keys]._mov_std = obj2.__dict__[item_keys]._mov_std\n",
    "            elif isinstance(obj1.__dict__[item_keys], rm.Model):\n",
    "                self._rec_copy(obj1.__dict__[item_keys], obj2.__dict__[item_keys])\n",
    "\n",
    "    def _update(self):\n",
    "        \"\"\"This function updates target network.\"\"\"\n",
    "        # A(B) Copy B to A.\n",
    "        self._target_q_network.copy_params(self._best_q_network)\n",
    "        self._rec_copy(self._target_q_network, self._best_q_network)\n",
    "\n",
    "    def _update_best_q_network(self):\n",
    "        \"\"\"This function updates best network in each target update period.\"\"\"\n",
    "        self._best_q_network.copy_params(self._q_network)\n",
    "        self._rec_copy(self._best_q_network, self._q_network)\n",
    "\n",
    "    @decorator([\"epoch\", \"epoch_step\", \"random_step\", \"test_step\"])\n",
    "    def fit(self, epoch=1, epoch_step=250000, random_step=50000,\n",
    "            batch_size=None, test_step=None,\n",
    "            update_period=None, train_frequency=None,\n",
    "            optimizer=None, gamma=None, buffer=None,\n",
    "            node_selector=None, test_node_selector=None,\n",
    "            action_filter=None, test_action_filter=None,\n",
    "            gradient_clipping=None, loss_func=None, initialize=None):\n",
    "\n",
    "        # acquiring arguments as local variables\n",
    "        epoch = fix_instance2(epoch, int, \"epoch\", positive=True, non_neg=True)\n",
    "        epoch_step = fix_instance2(epoch_step, int, \"epoch_step\", positive=True, non_neg=True)\n",
    "        random_step = fix_instance2(random_step, int, \"random_step\", positive=True)\n",
    "        test_step = fix_instance(test_step, None, None, \"test_step\", positive=True, non_neg=True)\n",
    "\n",
    "        _q_network = self._q_network\n",
    "        target_q_network = self._target_q_network\n",
    "        best_q_network = self._best_q_network\n",
    "        env = self._env\n",
    "        test_env = self._test_env\n",
    "        logger = self._logger\n",
    "        self._action_filter_during_fit = action_filter\n",
    "\n",
    "        buffer([1, ], test_env.state_shape)\n",
    "        buffer.set_network(_q_network,target_q_network,gamma)\n",
    "        \n",
    "        buffer2 = ReplayBuffer()\n",
    "        buffer2([1, ], test_env.state_shape)\n",
    "        buffer.set_network(_q_network,target_q_network,gamma)\n",
    "        \n",
    "        loss_func = fix_loss_function(loss_func, rm.ClippedMeanSquaredError())\n",
    "        # Reset Model\n",
    "        if initialize:\n",
    "            self._initializer()\n",
    "\n",
    "        # random step phase\n",
    "        print(\"Run random {} step for storing experiences\".format(random_step))\n",
    "\n",
    "        state = env.reset()\n",
    "\n",
    "        # env start(after reset)\n",
    "        env.start()\n",
    "\n",
    "        for i in range(1, random_step + 1):\n",
    "            action = env.sample()\n",
    "            next_state, reward, terminal = env.step(action)\n",
    "            \n",
    "#             if state[0] > 0:\n",
    "            if env.mode > 0:\n",
    "                buffer.store(state, np.array(action),\n",
    "                             np.array(reward), next_state, np.array(terminal))\n",
    "            else:\n",
    "                buffer2.store(state, np.array(action),\n",
    "                             np.array(reward), next_state, np.array(terminal))\n",
    "            state = next_state\n",
    "            if terminal:\n",
    "                state = env.reset()\n",
    "\n",
    "        # History of Learning\n",
    "        max_reward_in_each_update_period = -np.Inf\n",
    "\n",
    "        count = 0  # update period\n",
    "        step_count = 0  # steps\n",
    "        episode_count = 0  # episodes\n",
    "\n",
    "        # 1 epoch stores multiple epoch steps thus 1 epoch can hold multiple episodes\n",
    "        for e in range(1, epoch + 1):\n",
    "            continuous_step = 0\n",
    "            continuous_step_log = 0\n",
    "            sum_reward = 0\n",
    "            sum_reward_log = 0\n",
    "            nth_episode = 0\n",
    "\n",
    "            logger.start(epoch_step)\n",
    "\n",
    "            # env epoch\n",
    "            env.epoch()\n",
    "\n",
    "            state = env.reset()\n",
    "            loss = 0\n",
    "\n",
    "            for j in range(epoch_step):\n",
    "                # for stop epoch after 1 step\n",
    "                if j and env.stop_epoch():\n",
    "                    continue\n",
    "\n",
    "                # set action\n",
    "                act = self._action(state, node_selector, env)\n",
    "                action = action_filter(act, env.sample(),\n",
    "                                       step=step_count, episode=episode_count, epoch=e)\n",
    "                greedy = action_filter.value()\n",
    "\n",
    "                # pass it to env\n",
    "                next_state, reward, terminal = env.step(action)\n",
    "\n",
    "#                 if state[0] > 0:\n",
    "                if env.mode > 0:\n",
    "                    buffer.store(state, np.array(action),\n",
    "                             np.array(reward), next_state, np.array(terminal))\n",
    "                else:\n",
    "                    buffer2.store(state, np.array(action),\n",
    "                                 np.array(reward), next_state, np.array(terminal))\n",
    "\n",
    "               # env epoch step\n",
    "                env.epoch_step()\n",
    "\n",
    "                sum_reward += reward\n",
    "\n",
    "                if j % train_frequency == 0 and j:\n",
    "#                     if len(buffer) > batch_size:\n",
    "                    if len(buffer) > batch_size//2 and len(buffer2) > batch_size//2:\n",
    "                        train_prestate1, train_action1, train_reward1, train_state1, train_terminal1 = \\\n",
    "                            buffer.get_minibatch(batch_size//2)\n",
    "                        \n",
    "                        train_prestate2, train_action2, train_reward2, train_state2, train_terminal2 = \\\n",
    "                            buffer2.get_minibatch(batch_size//2)\n",
    "                        \n",
    "                        train_prestate = np.concatenate((train_prestate1,train_prestate2))\n",
    "                        train_action = np.concatenate((train_action1,train_action2))\n",
    "                        train_reward = np.concatenate((train_reward1,train_reward2))\n",
    "                        train_state = np.concatenate((train_state1,train_state2))\n",
    "                        train_terminal = np.concatenate((train_terminal1,train_terminal2))\n",
    "\n",
    "#                         train_prestate = train_prestate1\n",
    "#                         train_action = train_action1\n",
    "#                         train_reward = train_reward1\n",
    "#                         train_state = train_state1\n",
    "#                         train_terminal = train_terminal1\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        # getting q values as target reference\n",
    "                        _q_network.set_models(inference=True)\n",
    "                        target_q_network.set_models(inference=True)\n",
    "\n",
    "                        target = self._q_network(train_prestate, train_action).as_ndarray()\n",
    "\n",
    "                        target.setflags(write=True)\n",
    "                        \n",
    "                        \n",
    "                        n_action=np.zeros((batch_size,1))\n",
    "                        for i in range(batch_size):\n",
    "                            val_i = self._target_q_network(np.array([train_state[i] for _ in range(*env.action_shape)]), np.array(np.arange(*env.action_shape)).reshape(-1,1)).as_ndarray()\n",
    "                            n_action[i] = np.argmax(val_i.reshape(-1))\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        value = self._target_q_network(train_state, n_action).as_ndarray()\\\n",
    "                                        * gamma * (~train_terminal[:, None])\n",
    "                        \n",
    "#                         max_q_action = np.argmax(_q_network(train_state).as_ndarray(), axis=1)\n",
    "#                         value = target_q_network(train_state).as_ndarray()[(range(len(train_state)),\n",
    "#                                                                             max_q_action)][:, None] * gamma * (~train_terminal[:, None])\n",
    "\n",
    "                        # getting target value\n",
    "                        for i in range(batch_size):\n",
    "                            target[i] = train_reward[i] + value[i]\n",
    "\n",
    "                        # train\n",
    "                        _q_network.set_models(inference=False)\n",
    "                        with _q_network.train():\n",
    "                            z = self._q_network(train_prestate,train_action)\n",
    "                            ls = loss_func(z, target)\n",
    "                        grad = ls.grad()\n",
    "\n",
    "                        if gradient_clipping:\n",
    "                            gradient_clipping(grad)\n",
    "\n",
    "                        grad.update(optimizer)\n",
    "                        loss = np.sum(ls.as_ndarray())\n",
    "                        buffer.update()\n",
    "                        # train_loss += loss\n",
    "\n",
    "                if count % update_period == 0 and count:\n",
    "                    max_reward_in_each_update_period = -np.Inf\n",
    "                    self._update()\n",
    "                    count = 0\n",
    "                count += 1\n",
    "\n",
    "                # terminal reset\n",
    "                if terminal:\n",
    "                    if max_reward_in_each_update_period <= sum_reward:\n",
    "                        self._update_best_q_network()\n",
    "                        max_reward_in_each_update_period = sum_reward\n",
    "\n",
    "                    # train_sum_rewards_in_each_episode.append(sum_reward)\n",
    "                    # hold log values\n",
    "                    sum_reward_log = sum_reward\n",
    "                    continuous_step_log = continuous_step\n",
    "                    # reset log values\n",
    "                    sum_reward = 0\n",
    "                    continuous_step = 0\n",
    "                    # increment episode values\n",
    "                    nth_episode += 1\n",
    "                    episode_count += 1\n",
    "\n",
    "                    env.reset()\n",
    "\n",
    "                logger.update(1)\n",
    "                logger.logger(state=state, action=action, reward=reward,\n",
    "                              terminal=terminal, next_state=next_state,\n",
    "                              total_step=step_count, epoch_step=j, max_step=epoch_step,\n",
    "                              total_episode=episode_count, epoch_episode=nth_episode, steps_per_episode=continuous_step_log,\n",
    "                              epoch=e, max_epoch=epoch, loss=loss,\n",
    "                              sum_reward=sum_reward_log, epsilon=greedy)\n",
    "                # self.logger.update(1)\n",
    "\n",
    "                continuous_step += 1\n",
    "                step_count += 1\n",
    "                state = next_state\n",
    "\n",
    "                # if terminate executes, then do execute \"continue\"\n",
    "                if env.terminate() or env.terminate_epoch():\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                summed_test_reward = self.test(test_step, test_action_filter, test_node_selector)\n",
    "                logger.logger_epoch(total_episode=episode_count, epoch_episode=nth_episode,\n",
    "                                    epoch=e, max_epoch=epoch, test_reward=summed_test_reward, epsilon=greedy)\n",
    "                logger.close()\n",
    "                continue\n",
    "\n",
    "            logger.close()\n",
    "            if env.terminate():\n",
    "                break\n",
    "\n",
    "        # env close\n",
    "        env.close()\n",
    "\n",
    "    @test_decorator\n",
    "    def test(self, test_step=None, action_filter=None, node_selector=None):\n",
    "        \"\"\"\n",
    "        Test the trained agent.\n",
    "        Refer to ``DQN`` for other argument descriptions.\n",
    "\n",
    "        Args:\n",
    "            test_step (int, None): Number of steps (not episodes) for test. If None is given, this method tests execute only 1 episode.\n",
    "\n",
    "        Returns:\n",
    "            Sum of rewards. (float)\n",
    "        \"\"\"\n",
    "        env = self._test_env\n",
    "        # if filter_obj argument was specified, the change the object\n",
    "        test_step = fix_instance(test_step, None, int, \"test_step\", positive=True, non_neg=True)\n",
    "        # action_filter = fix_instance(action_filter, self._test_action_filter,\n",
    "        #                              EpsilonGreedyFilter, \"action_filter\")\n",
    "        # node_selector = fix_instance(node_selector, self._test_node_selector,\n",
    "        #                              DiscreteNodeChooser, \"node_selector\")\n",
    "        action_filter.check_instance(self._action_filter_during_fit)\n",
    "\n",
    "        sum_reward = 0\n",
    "        env.test_start()\n",
    "        state = env.reset()\n",
    "\n",
    "        if test_step is None:\n",
    "            while True:\n",
    "                action = action_filter.test(self._action(\n",
    "                    state, node_selector, env), env.sample())\n",
    "\n",
    "                state, reward, terminal = env.step(action)\n",
    "\n",
    "                sum_reward += float(reward)\n",
    "\n",
    "                env.test_epoch_step()\n",
    "\n",
    "                if terminal or env.test_terminate():\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            for j in range(test_step):\n",
    "                action = action_filter.test(self._action(\n",
    "                    state, node_selector, env), env.sample())\n",
    "\n",
    "                state, reward, terminal = env.step(action)\n",
    "\n",
    "                sum_reward += float(reward)\n",
    "\n",
    "                env.test_epoch_step()\n",
    "\n",
    "                if terminal:\n",
    "                    env.reset()\n",
    "\n",
    "                if env.test_terminate():\n",
    "                    break\n",
    "\n",
    "        env.test_close()\n",
    "\n",
    "        return sum_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renom_rl.environ import BaseEnv\n",
    "# from renom_rl.discrete.dqn import DQN\n",
    "import renom as rm\n",
    "from renom_rl.utility.filter import EpsilonSLFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Defining NN and Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from renom.utility.initializer import GlorotNormal\n",
    "\n",
    "class NN(rm.Model):\n",
    "    def __init__(self):\n",
    "        self.d1=rm.Dense(32)\n",
    "        self.d2=rm.Dense(32)\n",
    "        self.d3=rm.Dense(32)\n",
    "        self.d4=rm.Dense(1,initializer=GlorotNormal(gain=0.1))\n",
    "        \n",
    "        self.emb = rm.Embedding(32,6)\n",
    "        self.ad1 = rm.Dense(32)\n",
    "        self.r=rm.Relu()\n",
    "        \n",
    "    def forward(self,x,action):\n",
    "        h=self.d1(x)\n",
    "#         h=self.r(h)\n",
    "#         h=self.d2(h)\n",
    "#         h=self.r(h)\n",
    "        \n",
    "        a = self.emb(action)\n",
    "        a = self.r(a)\n",
    "        a = self.ad1(a)\n",
    "        a = self.r(a)\n",
    "        h = rm.concat(h,a)\n",
    "        h=self.d3(h)\n",
    "        h=self.r(h)\n",
    "        h=self.d4(h)\n",
    "        return h\n",
    "model=NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerEnv(BaseEnv):\n",
    "    def __init__(self, dataset, randomness=True):\n",
    "        self.action_shape=(len(p1),)\n",
    "        self.state_shape=(3+len(p1)*2,)\n",
    "        \n",
    "        self.idx = 0\n",
    "        self.l = len(dataset)\n",
    "        self.randomness = randomness\n",
    "        self.in_data = dataset[:,0:3]\n",
    "        self.out_data = dataset[:,3:5]\n",
    "        self.mode = 0\n",
    "        self._a_list=[]\n",
    "\n",
    "        \n",
    "    def reset(self):\n",
    "        self._a_list = []\n",
    "        self.mode = 0\n",
    "        \n",
    "        if self.randomness:\n",
    "            self.idx = np.random.randint(self.l)\n",
    "        else:\n",
    "            self.inc()\n",
    "            \n",
    "        self.state = np.concatenate((self.in_data[self.idx],np.zeros((len(p1)*2,)))) \n",
    "    \n",
    "        return self.state\n",
    "        \n",
    "    def step(self,action):\n",
    "        target = self.out_data[self.idx,self.mode]\n",
    "\n",
    "        if action in self._a_list:\n",
    "            raise Exception(\"{} already in list\".format(action))\n",
    "\n",
    "        self._a_list.append(action)\n",
    "        \n",
    "        if self.mode == 0:\n",
    "            self.state[3+action]= -0.2#1 - (len(self._a_list)-1)*0.2\n",
    "        else:\n",
    "            self.state[3+len(p1)+action]= -0.2#1 - (len(self._a_list)-1)*0.2\n",
    "            \n",
    "        if target==action:\n",
    "            reward = 1 - (len(self._a_list) - 1)*0.2\n",
    "            \n",
    "#             self.state = np.concatenate((self.in_data[self.idx],np.zeros((len(p1)*2,))))\n",
    "            \n",
    "            if self.mode == 0:\n",
    "                self.state = np.concatenate((self.in_data[self.idx],np.zeros((len(p1)*2,))))\n",
    "                self.state[3+action]=1\n",
    "                self.state2 = self.state\n",
    "            else:\n",
    "                self.state = self.state2\n",
    "                self.state[3+len(p1)+action]=1\n",
    "                \n",
    "            self.mode += 1\n",
    "            self._a_list = []\n",
    "            terminal = True if self.mode > 1 else False\n",
    "            \n",
    "        else:\n",
    "            reward = -1 #1 - 0.2*(len(self._a_list)-1)\n",
    "            terminal = False\n",
    "        \n",
    "        return self.state, reward, terminal\n",
    "    \n",
    "    def avail(self):\n",
    "        a_list = np.array(self._a_list)\n",
    "        a_range = np.arange(*self.action_shape)\n",
    "        a_avail = np.where(np.isin(a_range,a_list),0,1)\n",
    "        return  a_avail\n",
    "    \n",
    "    def sample(self):\n",
    "        \n",
    "        a_avail = self.avail()\n",
    "        tot = a_avail.sum()\n",
    "        a_prob = a_avail/tot if tot > 0 else a_avail\n",
    "\n",
    "        return np.random.choice(len(a_prob),p=a_prob)\n",
    "    \n",
    "    def index(self,x):\n",
    "        self.idx=x\n",
    "        \n",
    "    def inc(self):\n",
    "        self.idx += 1\n",
    "        self.idx %= self.l\n",
    "    \n",
    "    def mask(self):\n",
    "        \n",
    "        return self.avail()\n",
    "\n",
    "train_env=CustomerEnv(dataset)\n",
    "test_env=CustomerEnv(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn=DQN([train_env,test_env],\n",
    "        model,\n",
    "        gamma=0.8,\n",
    "        optimizer=rm.Adam(lr=0.001),\n",
    "        update_period=10,\n",
    "        batch_size=64,\n",
    "        action_filter=EpsilonSLFilter(epsilon_step=15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0001 epsilon 0.9979 loss 0.0000 rewards in epoch -9.600 episode 0006 rewards in episode -0.400.:   0%|          | 32/17000 [00:00<02:04, 136.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run random 0 step for storing experiences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 001 avg_loss:0.1498 total reward in epoch: [train:-682.400 test: 2.0] avg train reward in episode:-0.152 epsilon :0.000: 100%|██████████| 17000/17000 [04:54<00:00, 57.66it/s]\n"
     ]
    }
   ],
   "source": [
    "dqn.fit(epoch=1,epoch_step=17000,random_step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Result\n",
    "\n",
    "Here we show the reward for each epsiode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dqn._logger.graph(\"sum_reward\",average_range=[3,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 9.000e+00, 1.100e+01, 7.000e+00, 3.400e+01, 9.500e+01,\n",
       "        3.410e+02, 0.000e+00, 4.480e+02, 2.535e+03]),\n",
       " array([-10. ,  -8.8,  -7.6,  -6.4,  -5.2,  -4. ,  -2.8,  -1.6,  -0.4,\n",
       "          0.8,   2. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(dqn._logger.result()[\"sum_reward\"][1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the reward graph, we can observe the agent is making multiple mistakes in the beginning, but as it experience more steps, the agent gradually generates better reward value per episode.    \n",
    "The histogram of the reward represents the frequency of the total reward. From the reward graph, it might be seen as an oscilating graph, but from the histogram, we can observe that the agent is scoring +2 reward frequently, thus we can tell the agent is scoring good during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=softmax(model(np.array([[-1,-1,-1]+[0,0,0,0,0,0]+[0,0,0,0,0,0] for _ in range(6)]),np.arange(6)[...,None]).reshape(-1))\n",
    "a2=softmax(model(np.array([[1,1,1]+[0,0,0,0,0,0]+[0,0,0,0,0,0] for _ in range(6)]),np.arange(6)[...,None]).reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3053004  0.1491112  0.1389946  0.14735186 0.13700391 0.12223797]\n",
      "[0.13874242 0.24585988 0.14300686 0.17583103 0.14999518 0.14656456]\n",
      "0 0\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "print(a1)\n",
    "print(a2)\n",
    "print(0,np.argmax(a1))\n",
    "print(1,np.argmax(a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 0 0 0 a1: [-0.724519  -1.5464472 -1.3503065 -1.4770129 -1.6067648 -1.6603442]\n",
      "for 1 1 1 a1: [-1.7577423 -1.5436747 -2.1366546 -2.0434039 -1.8666538 -2.146932 ]\n",
      "for 2 2 2 a1: [-1.9188778 -1.841647  -1.2800441 -1.7886022 -1.7765087 -1.9192289]\n",
      "for 3 3 3 a1: [-1.8674328 -1.9518756 -1.7722968 -1.4154402 -1.8683001 -1.9640875]\n",
      "for 4 4 4 a1: [-0.9447209 -1.2641925 -1.5285832 -1.5645534 -0.6910663 -1.4532856]\n",
      "for 5 5 5 a1: [-2.5598881 -2.5737596 -2.2481258 -2.3358514 -2.3850286 -2.246285 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def result(x):\n",
    "    return np.argmax(softmax(model(np.array([x for _ in range(6)]),np.arange(6)[...,None]).reshape(-1)))\n",
    "\n",
    "# a1=softmax(model(np.array([-3,-3,-3]+[0,0,0,0,1,0]+[0,0,0,0,0,0])[None,...]))\n",
    "# a2=softmax(model(np.array([3,3,3]+[0,0,0,0,1,0]+[0,0,0,0,0,0])[None,...]))\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    z1 = [0 for _ in range(6)] \n",
    "    z2 = [0 for _ in range(6)] \n",
    "    z1[i] = 1\n",
    "    \n",
    "#     a1 = [-1,-1,-1] + z1 + z2\n",
    "#     a2 = [1,1,1] + z1 + z2\n",
    "    a1 = np.concatenate((x1[0],z1,z2))\n",
    "    a2 = np.concatenate((x2[0],z1,z2))\n",
    "    print(\"for {}\".format(i),result(a1),result(a2),\"a1:\",model(np.array([a1 for _ in range(6)]),np.arange(6)[...,None]).reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.10856306, -0.90026546, -0.97170215])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.15575737, 1.16424983, 0.94729081])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
